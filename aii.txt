// Code Name: Eight Puzzle Solver (Best First Search)
// Topic: Informed Search Algorithms - Best First Search
// Theory: Best First Search is an informed search algorithm that uses a heuristic to estimate the cost from the current node to the goal. In the 8-puzzle, the Manhattan distance heuristic is used, which sums the distances of each tile from its goal position. The algorithm always expands the node that appears to be closest to the goal, making it efficient for pathfinding in state spaces where a good heuristic is available.
// Explanation: This code solves the 8-puzzle problem using Best First Search. It finds a sequence of moves to reach the goal state from a given initial state, using the Manhattan distance as the heuristic to guide the search.

<code>
import numpy as np
from queue import PriorityQueue
import copy

# Example user input for interactive mode:
# Enter row 1: 1 2 3
# Enter row 2: 4 0 6
# Enter row 3: 7 5 8

class EightPuzzle:
    def __init__(self, initial_state=None):
        if initial_state is None:
            self.state = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 0]])
        else:
            self.state = np.array(initial_state)
        self.goal = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 0]])
        
    def get_blank_pos(self):
        pos = np.where(self.state == 0)
        return pos[0][0], pos[1][0]
    
    def get_manhattan_distance(self):
        distance = 0
        for i in range(3):
            for j in range(3):
                if self.state[i][j] != 0:
                    x, y = divmod(self.state[i][j] - 1, 3)
                    distance += abs(x - i) + abs(y - j)
        return distance
    
    def get_possible_moves(self):
        moves = []
        x, y = self.get_blank_pos()
        
        # Check all possible moves (up, down, left, right)
        for dx, dy in [(0, 1), (1, 0), (0, -1), (-1, 0)]:
            new_x, new_y = x + dx, y + dy
            if 0 <= new_x < 3 and 0 <= new_y < 3:
                new_state = copy.deepcopy(self.state)
                new_state[x][y], new_state[new_x][new_y] = new_state[new_x][new_y], new_state[x][y]
                moves.append(new_state)
        return moves
    
    def is_goal(self):
        return np.array_equal(self.state, self.goal)
    
    def solve(self):
        visited = set()
        pq = PriorityQueue()
        initial_cost = self.get_manhattan_distance()
        pq.put((initial_cost, self.state.tobytes(), [self.state.tolist()]))
        
        while not pq.empty():
            cost, state_bytes, path = pq.get()
            current_state = np.frombuffer(state_bytes, dtype=int).reshape(3, 3)
            
            if np.array_equal(current_state, self.goal):
                return path
            
            if state_bytes in visited:
                continue
                
            visited.add(state_bytes)
            self.state = current_state
            
            for next_state in self.get_possible_moves():
                if next_state.tobytes() not in visited:
                    self.state = next_state
                    new_cost = self.get_manhattan_distance()
                    new_path = path + [next_state.tolist()]
                    pq.put((new_cost, next_state.tobytes(), new_path))
        
        return None

def print_solution(path):
    for i, state in enumerate(path):
        print(f"Step {i}:")
        for row in state:
            print(row)
        print()

def main():
    # Example with user input
    print("Enter the initial state of the 8-puzzle (use 0 for empty space)")
    print("Enter each row with spaces between numbers:")
    initial_state = []
    for i in range(3):
        row = list(map(int, input(f"Enter row {i + 1}: ").strip().split()))
        initial_state.append(row)
    
    puzzle = EightPuzzle(initial_state)
    solution = puzzle.solve()
    
    if solution:
        print("\nSolution found!")
        print_solution(solution)
    else:
        print("\nNo solution found!")

// Code Name: Robot Navigation (Best First Search)
// Topic: Informed Search Algorithms - Best First Search
// Theory: Best First Search is an informed search strategy that uses a heuristic to guide the search towards the goal. In robot navigation, the Manhattan distance heuristic estimates the cost from the current cell to the goal, allowing the algorithm to efficiently find a path in a grid with obstacles. The algorithm always expands the node that appears closest to the goal according to the heuristic, making it suitable for pathfinding in grid-based environments.
// Explanation: This code finds a path for a robot from a start to a goal position in a 2D grid using Best First Search. Obstacles are represented as 1s, and free spaces as 0s. The algorithm uses the Manhattan distance to prioritize which cell to explore next.

<code>
import numpy as np
from queue import PriorityQueue

# Example user input for interactive mode:
# Enter the grid dimensions (rows cols): 5 5
# Enter the grid (5 rows, use 0 for free space and 1 for obstacles):
# 0 0 0 0 0
# 0 1 1 0 0
# 0 0 0 0 0
# 0 1 1 1 0
# 0 0 0 0 0
# Enter start position (row col): 0 0
# Enter goal position (row col): 4 4

class RobotNavigation:
    def __init__(self, grid=None, start=None, goal=None):
        if grid is None:
            self.grid = np.array([
                [0, 0, 0, 0, 0],
                [0, 1, 1, 0, 0],
                [0, 0, 0, 0, 0],
                [0, 1, 1, 1, 0],
                [0, 0, 0, 0, 0]
            ])  # 0 represents free space, 1 represents obstacle
        else:
            self.grid = np.array(grid)
            
        self.rows, self.cols = self.grid.shape
        self.start = start if start else (0, 0)
        self.goal = goal if goal else (self.rows-1, self.cols-1)
    
    def get_manhattan_distance(self, pos):
        return abs(pos[0] - self.goal[0]) + abs(pos[1] - self.goal[1])
    
    def get_neighbors(self, pos):
        neighbors = []
        for dx, dy in [(0, 1), (1, 0), (0, -1), (-1, 0)]:  # right, down, left, up
            new_x, new_y = pos[0] + dx, pos[1] + dy
            if (0 <= new_x < self.rows and 
                0 <= new_y < self.cols and 
                self.grid[new_x][new_y] == 0):
                neighbors.append((new_x, new_y))
        return neighbors
    
    def solve(self):
        visited = set()
        pq = PriorityQueue()
        
        # Priority queue items: (manhattan_distance, current_position, path)
        initial_cost = self.get_manhattan_distance(self.start)
        pq.put((initial_cost, self.start, [self.start]))
        
        while not pq.empty():
            cost, current_pos, path = pq.get()
            
            if current_pos == self.goal:
                return path
            
            if current_pos in visited:
                continue
                
            visited.add(current_pos)
            
            for next_pos in self.get_neighbors(current_pos):
                if next_pos not in visited:
                    new_cost = self.get_manhattan_distance(next_pos)
                    new_path = path + [next_pos]
                    pq.put((new_cost, next_pos, new_path))
        
        return None

def print_path_on_grid(grid, path):
    grid_copy = grid.copy()
    for i, (x, y) in enumerate(path):
        if i == 0:
            grid_copy[x][y] = 'S'  # Start
        elif i == len(path) - 1:
            grid_copy[x][y] = 'G'  # Goal
        else:
            grid_copy[x][y] = '*'  # Path
    
    print("\nPath visualization ('S': Start, 'G': Goal, '*': Path, '1': Obstacle, '0': Free space):")
    for row in grid_copy:
        print(' '.join(str(cell) for cell in row))

def main():
    # Example with user input
    print("Enter the grid dimensions (rows cols):")
    rows, cols = map(int, input().strip().split())
    
    print(f"Enter the grid ({rows} rows, use 0 for free space and 1 for obstacles):")
    grid = []
    for _ in range(rows):
        row = list(map(int, input().strip().split()))
        grid.append(row)
    
    print("Enter start position (row col):")
    start = tuple(map(int, input().strip().split()))
    
    print("Enter goal position (row col):")
    goal = tuple(map(int, input().strip().split()))
    
    robot = RobotNavigation(grid, start, goal)
    path = robot.solve()
    
    if path:
        print("\nSolution found!")
        print("Path:", path)
        print_path_on_grid(robot.grid, path)
    else:
        print("\nNo solution found!")

// Code Name: Cities Distance Shortest Path (Best First Search)
// Topic: Informed Search Algorithms - Best First Search
// Theory: Best First Search uses a heuristic to estimate the cost from the current node to the goal. In the context of finding the shortest path between cities, the heuristic can be the shortest path length in the current graph. The algorithm expands the node that appears to be closest to the goal, making it efficient for pathfinding in graphs where a good heuristic is available.
// Explanation: This code finds the shortest path between two cities in a graph using Best First Search. The cities and distances are represented as a graph, and the algorithm uses the shortest path length as a heuristic to guide the search.

<code>
import networkx as nx
from queue import PriorityQueue

# Example user input for interactive mode:
# Enter number of cities: 3
# Enter city details (name latitude longitude):
# A 0 0
# B 0 1
# C 1 1
# Enter number of connections: 3
# Enter connections (city1 city2 distance):
# A B 1
# B C 1
# A C 2
# Enter start city: A
# Enter end city: C

class CitiesDistance:
    def __init__(self, cities=None, distances=None):
        self.graph = nx.Graph()
        
        if cities is None or distances is None:
            # Default example with some Indian cities
            self.cities = {
                'Mumbai': (19.0760, 72.8777),
                'Delhi': (28.6139, 77.2090),
                'Bangalore': (12.9716, 77.5946),
                'Chennai': (13.0827, 80.2707),
                'Kolkata': (22.5726, 88.3639)
            }
            
            # Example distances in kilometers
            self.distances = [
                ('Mumbai', 'Delhi', 1427),
                ('Mumbai', 'Bangalore', 981),
                ('Delhi', 'Kolkata', 1305),
                ('Bangalore', 'Chennai', 346),
                ('Chennai', 'Kolkata', 1659),
                ('Mumbai', 'Chennai', 1338),
                ('Delhi', 'Bangalore', 2150)
            ]
        else:
            self.cities = cities
            self.distances = distances
        
        self._build_graph()
    
    def _build_graph(self):
        # Add all cities to the graph
        for city, coords in self.cities.items():
            self.graph.add_node(city, pos=coords)
        
        # Add all distances as edges
        for city1, city2, distance in self.distances:
            self.graph.add_edge(city1, city2, weight=distance)
    
    def get_distance(self, city1, city2):
        try:
            return nx.shortest_path_length(self.graph, city1, city2, weight='weight')
        except nx.NetworkXNoPath:
            return float('inf')
    
    def solve(self, start_city, end_city):
        if start_city not in self.cities or end_city not in self.cities:
            return None
        
        visited = set()
        pq = PriorityQueue()
        
        # Priority queue items: (estimated_total_distance, current_city, path, total_distance)
        initial_distance = self.get_distance(start_city, end_city)
        pq.put((initial_distance, start_city, [start_city], 0))
        
        while not pq.empty():
            _, current_city, path, distance = pq.get()
            
            if current_city == end_city:
                return path, distance
            
            if current_city in visited:
                continue
            
            visited.add(current_city)
            
            for neighbor in self.graph.neighbors(current_city):
                if neighbor not in visited:
                    edge_distance = self.graph[current_city][neighbor]['weight']
                    new_distance = distance + edge_distance
                    estimated_remaining = self.get_distance(neighbor, end_city)
                    new_path = path + [neighbor]
                    pq.put((new_distance + estimated_remaining, neighbor, new_path, new_distance))
        
        return None

def main():
    # Example with user input
    print("Enter number of cities:")
    n = int(input())
    
    cities = {}
    print("Enter city details (name latitude longitude):")
    for _ in range(n):
        name, lat, lon = input().strip().split()
        cities[name] = (float(lat), float(lon))
    
    print("Enter number of connections:")
    m = int(input())
    
    distances = []
    print("Enter connections (city1 city2 distance):")
    for _ in range(m):
        city1, city2, dist = input().strip().split()
        distances.append((city1, city2, float(dist)))
    
    router = CitiesDistance(cities, distances)
    
    print("Enter start city:")
    start_city = input().strip()
    print("Enter end city:")
    end_city = input().strip()
    
    result = router.solve(start_city, end_city)
    
    if result:
        path, distance = result
        print("\nPath found!")
        print("Route:", " -> ".join(path))
        print(f"Total distance: {distance} km")
    else:
        print("\nNo path found!")

// Code Name: Cities Distance with Haversine Distance (A* Search)
// Topic: Informed Search Algorithms - A* Search
// Theory: A* Search is a best-first search algorithm that finds the shortest path from a start node to a goal node using a cost function f(n) = g(n) + h(n). In the context of cities, g(n) is the path cost so far, and h(n) is the Haversine (great-circle) distance between the current city and the goal, which provides an admissible heuristic for real-world distances. A* is optimal and complete if the heuristic is admissible and consistent.
// Explanation: This code finds the shortest path between two cities in a graph using the A* algorithm. The heuristic is the Haversine distance between cities, making the search more realistic for geographical data.

<code>
import networkx as nx
from queue import PriorityQueue
import math

# Example user input for interactive mode:
# Enter number of cities: 3
# Enter city details (name latitude longitude):
# A 0 0
# B 0 1
# C 1 1
# Enter number of connections: 3
# Enter connections (city1 city2 distance):
# A B 1
# B C 1
# A C 2
# Enter start city: A
# Enter end city: C

class CitiesDistance:
    def __init__(self, cities=None, distances=None):
        self.graph = nx.Graph()
        
        if cities is None or distances is None:
            # Default example with some Indian cities
            self.cities = {
                'Mumbai': (19.0760, 72.8777),
                'Delhi': (28.6139, 77.2090),
                'Bangalore': (12.9716, 77.5946),
                'Chennai': (13.0827, 80.2707),
                'Kolkata': (22.5726, 88.3639)
            }
            
            # Example distances in kilometers
            self.distances = [
                ('Mumbai', 'Delhi', 1427),
                ('Mumbai', 'Bangalore', 981),
                ('Delhi', 'Kolkata', 1305),
                ('Bangalore', 'Chennai', 346),
                ('Chennai', 'Kolkata', 1659),
                ('Mumbai', 'Chennai', 1338),
                ('Delhi', 'Bangalore', 2150)
            ]
        else:
            self.cities = cities
            self.distances = distances
        
        self._build_graph()
        
        # Dictionary to store g_scores
        self.g_scores = {}
    
    def _build_graph(self):
        # Add all cities to the graph
        for city, coords in self.cities.items():
            self.graph.add_node(city, pos=coords)
        
        # Add all distances as edges
        for city1, city2, distance in self.distances:
            self.graph.add_edge(city1, city2, weight=distance)
    
    def get_haversine_distance(self, city1, city2):
        """Calculate the great circle distance between two cities using their coordinates."""
        lat1, lon1 = self.cities[city1]
        lat2, lon2 = self.cities[city2]
        
        # Convert to radians
        lat1, lon1 = math.radians(lat1), math.radians(lon1)
        lat2, lon2 = math.radians(lat2), math.radians(lon2)
        
        # Haversine formula
        dlat = lat2 - lat1
        dlon = lon2 - lon1
        a = (math.sin(dlat/2)**2 + 
             math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2)
        c = 2 * math.asin(math.sqrt(a))
        r = 6371  # Radius of Earth in kilometers
        
        return c * r
    
    def solve(self, start_city, end_city):
        if start_city not in self.cities or end_city not in self.cities:
            return None
        
        visited = set()
        pq = PriorityQueue()
        self.g_scores = {start_city: 0}
        
        # Priority queue items: (f_score, current_city, path, total_distance)
        h_score = self.get_haversine_distance(start_city, end_city)
        pq.put((h_score, start_city, [start_city], 0))
        
        while not pq.empty():
            f_score, current_city, path, distance = pq.get()
            
            if current_city == end_city:
                return path, distance
            
            if current_city in visited:
                continue
            
            visited.add(current_city)
            
            for neighbor in self.graph.neighbors(current_city):
                if neighbor not in visited:
                    edge_distance = self.graph[current_city][neighbor]['weight']
                    tentative_g_score = self.g_scores[current_city] + edge_distance
                    
                    if (neighbor not in self.g_scores or 
                        tentative_g_score < self.g_scores[neighbor]):
                        
                        self.g_scores[neighbor] = tentative_g_score
                        h_score = self.get_haversine_distance(neighbor, end_city)
                        f_score = tentative_g_score + h_score
                        new_path = path + [neighbor]
                        pq.put((f_score, neighbor, new_path, tentative_g_score))
        
        return None

def main():
    # Example with user input
    print("Enter number of cities:")
    n = int(input())
    
    cities = {}
    print("Enter city details (name latitude longitude):")
    for _ in range(n):
        name, lat, lon = input().strip().split()
        cities[name] = (float(lat), float(lon))
    
    print("Enter number of connections:")
    m = int(input())
    
    distances = []
    print("Enter connections (city1 city2 distance):")
    for _ in range(m):
        city1, city2, dist = input().strip().split()
        distances.append((city1, city2, float(dist)))
    
    router = CitiesDistance(cities, distances)
    
    print("Enter start city:")
    start_city = input().strip()
    print("Enter end city:")
    end_city = input().strip()
    
    result = router.solve(start_city, end_city)
    
    if result:
        path, distance = result
        print("\nPath found!")
        print("Route:", " -> ".join(path))
        print(f"Total distance: {distance:.2f} km")
    else:
        print("\nNo path found!")

// Code Name: Map Coloring Solver (Constraint Satisfaction)
// Topic: Constraint Satisfaction Problems (CSP)
// Theory: Map coloring is a classic CSP where each region is a variable, the domain is a set of colors, and constraints ensure that no two adjacent regions have the same color. The problem is solved by assigning colors to regions such that all constraints are satisfied, using backtracking and heuristics like MRV and LCV.
// Explanation: This code solves the map coloring problem for a given set of regions and borders, using backtracking and heuristics to efficiently search for a valid coloring.

<code>
import networkx as nx
from typing import Dict, List, Set

# Example user input for interactive mode:
# Enter number of regions: 3
# Enter region names:
# A
# B
# C
# Enter number of borders: 3
# Enter borders (region1 region2):
# A B
# B C
# A C
# Enter number of colors (or press Enter to use default colors):
# (Press Enter)

class MapColoringSolver:
    def __init__(self, regions: List[str], borders: List[tuple], colors: List[str] = None):
        self.regions = regions
        self.borders = borders
        self.colors = colors if colors else ['Red', 'Green', 'Blue', 'Yellow']
        self.graph = nx.Graph()
        self._build_graph()
        
    def _build_graph(self):
        self.graph.add_nodes_from(self.regions)
        self.graph.add_edges_from(self.borders)
    
    def _is_safe(self, region: str, color: str, coloring: Dict[str, str]) -> bool:
        for neighbor in self.graph.neighbors(region):
            if neighbor in coloring and coloring[neighbor] == color:
                return False
        return True
    
    def _get_unassigned_region(self, coloring: Dict[str, str]) -> str:
        min_remaining = float('inf')
        chosen_region = None
        for region in self.regions:
            if region not in coloring:
                legal_colors = sum(1 for color in self.colors 
                                 if self._is_safe(region, color, coloring))
                if legal_colors < min_remaining:
                    min_remaining = legal_colors
                    chosen_region = region
        return chosen_region
    
    def _get_ordered_colors(self, region: str, coloring: Dict[str, str]) -> List[str]:
        color_scores = []
        for color in self.colors:
            if self._is_safe(region, color, coloring):
                coloring[region] = color
                score = 0
                for neighbor in self.graph.neighbors(region):
                    if neighbor not in coloring:
                        score += sum(1 for c in self.colors 
                                   if self._is_safe(neighbor, c, coloring))
                color_scores.append((score, color))
                del coloring[region]
        return [color for score, color in sorted(color_scores, reverse=True)]
    
    def _solve(self, coloring: Dict[str, str]) -> Dict[str, str]:
        if len(coloring) == len(self.regions):
            return coloring
        region = self._get_unassigned_region(coloring)
        if not region:
            return None
        for color in self._get_ordered_colors(region, coloring):
            if self._is_safe(region, color, coloring):
                coloring[region] = color
                result = self._solve(coloring)
                if result:
                    return result
                del coloring[region]
        return None
    
    def solve(self) -> Dict[str, str]:
        return self._solve({})

def print_solution(regions: List[str], solution: Dict[str, str]):
    max_region_len = max(len(region) for region in regions)
    max_color_len = max(len(color) for color in solution.values())
    print("\nSolution:")
    print("=" * (max_region_len + max_color_len + 7))
    for region in sorted(regions):
        print(f"{region:<{max_region_len}} | {solution[region]}")
    print("=" * (max_region_len + max_color_len + 7))

def main():
    print("Enter number of regions:")
    n = int(input())
    print("Enter region names:")
    regions = []
    for _ in range(n):
        regions.append(input().strip())
    print("Enter number of borders:")
    m = int(input())
    print("Enter borders (region1 region2):")
    borders = []
    for _ in range(m):
        r1, r2 = input().strip().split()
        borders.append((r1, r2))
    print("Enter number of colors (or press Enter to use default colors):")
    colors_input = input().strip()
    if colors_input:
        print("Enter colors:")
        colors = []
        for _ in range(int(colors_input)):
            colors.append(input().strip())
    else:
        colors = None
    solver = MapColoringSolver(regions, borders, colors)
    solution = solver.solve()
    if solution:
        print_solution(regions, solution)
    else:
        print("\nNo solution found!")

if __name__ == "__main__":
    main() 

// Code Name: POS Tagger using NLTK and spaCy
// Topic: Natural Language Processing (NLP) - Part-of-Speech Tagging
// Theory: POS tagging assigns grammatical categories (noun, verb, adjective, etc.) to each word in a sentence. Statistical and rule-based taggers (like NLTK and spaCy) use pre-trained models to label words based on context and word features.
// Explanation: This code tags each word in a user-provided sentence using either spaCy or NLTK, and explains each tag.
// Example user input:
// Enter text to analyze (or press Enter for default example): The quick brown fox jumps over the lazy dog.
// Choose tagger:
// 1. spaCy (more accurate, slower)
// 2. NLTK (faster, less accurate)
// Enter choice (1 or 2): 1

<code>
import nltk
import spacy
from typing import List, Tuple

class POSTagger:
    def __init__(self, use_spacy: bool = True):
        self.use_spacy = use_spacy
        if use_spacy:
            try:
                self.nlp = spacy.load('en_core_web_sm')
            except OSError:
                print("Downloading spaCy English model...")
                spacy.cli.download('en_core_web_sm')
                self.nlp = spacy.load('en_core_web_sm')
        else:
            try:
                nltk.data.find('tokenizers/punkt')
                nltk.data.find('taggers/averaged_perceptron_tagger')
            except LookupError:
                print("Downloading required NLTK data...")
                nltk.download('punkt')
                nltk.download('averaged_perceptron_tagger')

    def tag_text(self, text: str) -> List[Tuple[str, str]]:
        if self.use_spacy:
            doc = self.nlp(text)
            return [(token.text, token.pos_) for token in doc]
        else:
            tokens = nltk.word_tokenize(text)
            return nltk.pos_tag(tokens)

    def explain_tags(self, tagged_text: List[Tuple[str, str]]) -> List[Tuple[str, str, str]]:
        tag_explanations = {
            'ADJ': 'Adjective',
            'ADP': 'Adposition (preposition or postposition)',
            'ADV': 'Adverb',
            'AUX': 'Auxiliary verb',
            'CCONJ': 'Coordinating conjunction',
            'DET': 'Determiner',
            'INTJ': 'Interjection',
            'NOUN': 'Noun',
            'NUM': 'Numeral',
            'PART': 'Particle',
            'PRON': 'Pronoun',
            'PROPN': 'Proper noun',
            'PUNCT': 'Punctuation',
            'SCONJ': 'Subordinating conjunction',
            'SYM': 'Symbol',
            'VERB': 'Verb',
            'X': 'Other',
            'CC': 'Coordinating conjunction',
            'CD': 'Cardinal number',
            'DT': 'Determiner',
            'EX': 'Existential there',
            'FW': 'Foreign word',
            'IN': 'Preposition or subordinating conjunction',
            'JJ': 'Adjective',
            'JJR': 'Adjective, comparative',
            'JJS': 'Adjective, superlative',
            'LS': 'List item marker',
            'MD': 'Modal',
            'NN': 'Noun, singular or mass',
            'NNS': 'Noun, plural',
            'NNP': 'Proper noun, singular',
            'NNPS': 'Proper noun, plural',
            'PDT': 'Predeterminer',
            'POS': 'Possessive ending',
            'PRP': 'Personal pronoun',
            'PRP$': 'Possessive pronoun',
            'RB': 'Adverb',
            'RBR': 'Adverb, comparative',
            'RBS': 'Adverb, superlative',
            'RP': 'Particle',
            'TO': 'to',
            'UH': 'Interjection',
            'VB': 'Verb, base form',
            'VBD': 'Verb, past tense',
            'VBG': 'Verb, gerund or present participle',
            'VBN': 'Verb, past participle',
            'VBP': 'Verb, non-3rd person singular present',
            'VBZ': 'Verb, 3rd person singular present',
            'WDT': 'Wh-determiner',
            'WP': 'Wh-pronoun',
            'WP$': 'Possessive wh-pronoun',
            'WRB': 'Wh-adverb'
        }
        return [(word, tag, tag_explanations.get(tag, 'Unknown tag')) 
                for word, tag in tagged_text]

def print_tagged_text(tagged_text: List[Tuple[str, str, str]]):
    max_word_len = max(len(word) for word, _, _ in tagged_text)
    max_tag_len = max(len(tag) for _, tag, _ in tagged_text)
    print("\nPOS Tagging Results:")
    print("=" * (max_word_len + max_tag_len + 50))
    print(f"{'Word':<{max_word_len}} | {'Tag':<{max_tag_len}} | Explanation")
    print("-" * (max_word_len + max_tag_len + 50))
    for word, tag, explanation in tagged_text:
        print(f"{word:<{max_word_len}} | {tag:<{max_tag_len}} | {explanation}")
    print("=" * (max_word_len + max_tag_len + 50))

def main():
    print("Enter text to analyze (or press Enter for default example):")
    text = input().strip()
    if not text:
        text = "The quick brown fox jumps over the lazy dog."
        print(f"\nUsing default example: '{text}'")
    print("\nChoose tagger:")
    print("1. spaCy (more accurate, slower)")
    print("2. NLTK (faster, less accurate)")
    choice = input("Enter choice (1 or 2): ").strip()
    use_spacy = choice != "2"
    tagger = POSTagger(use_spacy)
    tagged_text = tagger.tag_text(text)
    explained_tags = tagger.explain_tags(tagged_text)
    print_tagged_text(explained_tags)

if __name__ == "__main__":
    main() 

// Code Name: Tic Tac Toe (Minimax AI)
// Topic: Game AI - Minimax Algorithm
// Theory: The Minimax algorithm is a recursive decision-making strategy used in two-player, turn-based games. It simulates all possible moves, assuming both players play optimally, and chooses the move that maximizes the AI's minimum gain (hence "minimax"). In Tic Tac Toe, this guarantees the AI will never lose if it plays first or responds optimally.
// Explanation: This code implements a Tic Tac Toe game where the user plays against an AI using the Minimax algorithm. The AI always plays as 'X', the user as 'O'. The board is displayed after each move, and the user is prompted for input until the game ends.
// Example user input:
// Enter your move (1-9): 5
// (Continue entering numbers 1-9 for your moves as prompted)
// Would you like to play again? (y/n): n

<code>
class TicTacToe:
    def __init__(self):
        self.board = [[' ' for _ in range(3)] for _ in range(3)]
        self.current_player = 'X'
    def print_board(self):
        print("\nCurrent Board:")
        print("-------------")
        for i, row in enumerate(self.board):
            print("|", end=" ")
            for j, cell in enumerate(row):
                print(cell if cell != ' ' else str(i*3 + j + 1), end=" | ")
            print("\n-------------")
    def is_winner(self, player):
        for row in self.board:
            if all(cell == player for cell in row):
                return True
        for col in range(3):
            if all(self.board[row][col] == player for row in range(3)):
                return True
        if all(self.board[i][i] == player for i in range(3)):
            return True
        if all(self.board[i][2-i] == player for i in range(3)):
            return True
        return False
    def is_board_full(self):
        return all(cell != ' ' for row in self.board for cell in row)
    def get_empty_cells(self):
        empty = []
        for i in range(3):
            for j in range(3):
                if self.board[i][j] == ' ':
                    empty.append((i, j))
        return empty
    def make_move(self, row, col, player):
        if self.board[row][col] == ' ':
            self.board[row][col] = player
            return True
        return False
    def undo_move(self, row, col):
        self.board[row][col] = ' '
    def minimax(self, depth, is_maximizing):
        if self.is_winner('X'):
            return 1
        if self.is_winner('O'):
            return -1
        if self.is_board_full():
            return 0
        if is_maximizing:
            best_score = float('-inf')
            for row, col in self.get_empty_cells():
                self.make_move(row, col, 'X')
                score = self.minimax(depth + 1, False)
                self.undo_move(row, col)
                best_score = max(score, best_score)
            return best_score
        else:
            best_score = float('inf')
            for row, col in self.get_empty_cells():
                self.make_move(row, col, 'O')
                score = self.minimax(depth + 1, True)
                self.undo_move(row, col)
                best_score = min(score, best_score)
            return best_score
    def get_best_move(self):
        best_score = float('-inf')
        best_move = None
        for row, col in self.get_empty_cells():
            self.make_move(row, col, 'X')
            score = self.minimax(0, False)
            self.undo_move(row, col)
            if score > best_score:
                best_score = score
                best_move = (row, col)
        return best_move
    def play_game(self):
        print("Welcome to Tic Tac Toe!")
        print("You are O and the AI is X")
        print("Positions are numbered from 1-9, left to right, top to bottom")
        while True:
            self.print_board()
            print("\nAI's turn (X)...")
            row, col = self.get_best_move()
            self.make_move(row, col, 'X')
            if self.is_winner('X'):
                self.print_board()
                print("\nAI wins!")
                break
            if self.is_board_full():
                self.print_board()
                print("\nIt's a tie!")
                break
            self.print_board()
            while True:
                try:
                    pos = int(input("\nEnter your move (1-9): ")) - 1
                    row, col = pos // 3, pos % 3
                    if 0 <= row < 3 and 0 <= col < 3 and self.board[row][col] == ' ':
                        self.make_move(row, col, 'O')
                        break
                    else:
                        print("Invalid move! Try again.")
                except (ValueError, IndexError):
                    print("Invalid input! Please enter a number between 1 and 9.")
            if self.is_winner('O'):
                self.print_board()
                print("\nCongratulations! You win!")
                break
            if self.is_board_full():
                self.print_board()
                print("\nIt's a tie!")
                break

def main():
    while True:
        game = TicTacToe()
        game.play_game()
        play_again = input("\nWould you like to play again? (y/n): ").lower()
        if play_again != 'y':
            print("\nThanks for playing!")
            break

if __name__ == "__main__":
    main() 

// Code Name: Crossword Solver (Constraint Satisfaction)
// Topic: Constraint Satisfaction Problems (CSP)
// Theory: Crossword solving as a CSP involves filling a grid with words such that all constraints are satisfied: words must fit in the available slots, intersecting letters must match, and only valid words are used. The problem is solved using backtracking and heuristics to efficiently search for a valid assignment.
# Example input:
# 10
# +-++++++++
# +-++++++++
# +-++++++++
# +-----++++
# +-+++-++++
# +-+++-++++
# +++++-++++
# ++------++
# +++++-++++
# +++++-++++
# LONDON;DELHI;ICELAND;ANKARA;CALIFORNIA;NIGERIA;CANADA;TELAVIV
#
# Example output:
# +L++++++++
# +O++++++++
# +N++++++++
# +DELHI++++
# +O+++C++++
# +N+++A++++
# +++++N++++
# ++ANKARA++
# +++++I++++
# +++++A++++

import math
import os
import random
import re
import sys

def crosswordPuzzle(crossword, words):
    words = words.split(";")
    class Variable():
        def __init__(self, length, start, stop, direction):
            self.length = length
            self.start = start
            self.stop = stop
            self.start_i, self.start_j = start
            self.stop_i, self.stop_j = stop
            self.cells = set([
                (i, self.start_j) for i in range(self.start_i, self.stop_i + 1)
            ] if direction == "down" else [
                (self.start_i, j) for j in range(self.start_j, self.stop_j + 1)
            ])
            self.direction = direction
            
    def creating_variables():
        variables = []
        for i in range(len(crossword)):
            for j in range(len(crossword)):
                startsword = False
                if crossword[i][j] == "-":
                    if i != len(crossword) - 1 and i != 0:
                        if (crossword[i - 1][j] == "+" or crossword[i - 1][j] == "X") and crossword[i + 1][j] == "-":
                            startsword = True
                    elif i == 0:
                        if crossword[i + 1][j] == "-":
                            startsword = True
                if startsword:
                    length = 0
                    end = 0
                    for k in range(i, len(crossword)):
                        if crossword[k][j] == "-":
                            length += 1
                            end = k
                        else:
                            break
                    var = Variable(length, (i, j), (end, j), "down")
                    variables.append(var)
                if startsword:
                    continue
                if crossword[i][j] == "-":
                    if j != len(crossword) - 1 and j != 0:
                        if (crossword[i][j - 1] == "+" or crossword[i][j - 1] == "X") and crossword[i][j + 1] == "-":
                            startsword = True
                    elif j == 0:
                        if crossword[i][j + 1] == "-":
                            startsword = True
                if startsword:
                    length = 0
                    end = 0
                    for k in range(j, len(crossword)):
                        if crossword[i][k] == "-":
                            length += 1
                            end = k
                        else:
                            break
                    var = Variable(length, (i, j), (i, end), "across")
                    if var.length > 2:
                        variables.append(var)
        return variables
    
    def unassigned(assignment):
        var = domains.keys() - assignment.keys()
        unassigned_var = random.choice(list(var))
        return unassigned_var
    
    def overlaps(var, n_var):
        intersection = var.cells.intersection(n_var.cells)
        if intersection:
            inter_pos = []
            inter_i, inter_j = intersection.pop()
            for variable in (var, n_var):
                if variable.direction == "down":
                    pos_var = inter_i - variable.start_i
                else:
                    pos_var = inter_j - variable.start_j
                inter_pos.append(pos_var)        
            return inter_pos
            
    def node_consistency():
        for var in domains:
            for val in domains[var].copy():
                if var.length != len(val):
                    domains[var].remove(val)
                    
    def consistent(var, assignment):
        if var.length != len(assignment[var]):
            return False
        
        for other_var in assignment:
            if other_var == var:
                continue
            overlap = overlaps(var, other_var)
            if overlap:
                i, j = overlap
                if assignment[var][i] != assignment[other_var][j]:
                    return False
        return True
        
    def backtracking(assignment):
        if len(assignment) == len(domains):
            return assignment
        
        result = None
        var = unassigned(assignment)
        for val in domains[var].copy():
            new_assignment = assignment.copy()
            new_assignment[var] = val
            if consistent(var, new_assignment):
                result = backtracking(new_assignment)
            if result:
                return result
            del new_assignment
            
        return result
    
    def printer(assignment):
        if not assignment:
            return "NO solution"
        
        board = []
        for lines in crossword:
            lines = list(lines)
            board.append(lines)

        
        for var in assignment:
            i, j = var.start
            for val in range(var.length):
                if var.direction == "down":
                    board[i + val][j] = assignment[var][val]
                if var.direction == "across":
                    board[i][j + val] = assignment[var][val]
        # print(board)
        for t in range(len(board)):
            crossword[t] = "".join(board[t])
        return crossword
    
    variables = creating_variables()
    # for vari in variables:
    #     print(vari)
    #     print(vari.length)
    #     print(vari.cells)
    #     print("\n")
    domains = {}
    for i in variables:
        domains[i] = set(words)
    node_consistency()
    prior_assignment = {
        var: domains[var].copy().pop() for var in domains if len(domains[var]) == 1
    }
    assignment = backtracking(prior_assignment)
    return printer(assignment)
    
    
    
if __name__ == '__main__':
    print("Enter number of rows in the crossword grid:")
    n = int(input())
    print(f"Enter the {n}x{n} crossword grid (use '+' for black squares, '-' for empty squares):")
    crossword = []
    for _ in range(n):
        crossword.append(input())
    print("Enter words separated by semicolons (e.g. LONDON;DELHI;ICELAND):")
    words = input()
    result = crosswordPuzzle(crossword, words)
    print("\nSolved crossword:")
    for line in result:
        print(line)

// Code Name: Cryptarithmetic Solver (Constraint Satisfaction)
// Topic: Constraint Satisfaction Problems (CSP)
// Theory: Cryptarithmetic puzzles are CSPs where each letter represents a unique digit. The constraints are that no two letters can have the same digit, and the arithmetic equation must be satisfied. The problem is solved by searching all possible assignments using backtracking and checking constraints at each step.
// Explanation: This code solves a user-defined cryptarithmetic puzzle (e.g., SEND + MORE = MONEY) by assigning digits to letters such that the equation holds. It uses permutations to try all possible assignments and prints all valid solutions.
// Example user input:
// First word: SEND
// Second word: MORE
// Result word: MONEY

<code>
from itertools import permutations

class CryptarithmeticSolver:
    def __init__(self, word1, word2, result):
        self.word1 = word1.upper()
        self.word2 = word2.upper()
        self.result = result.upper()
        self.letters = list(set(word1.upper() + word2.upper() + result.upper()))
        self.solutions = []
    def is_valid_solution(self, letter_values):
        mapping = dict(zip(self.letters, letter_values))
        if (mapping[self.word1[0]] == 0 or 
            mapping[self.word2[0]] == 0 or 
            mapping[self.result[0]] == 0):
            return False
        num1 = sum(mapping[c] * (10 ** i) for i, c in enumerate(reversed(self.word1)))
        num2 = sum(mapping[c] * (10 ** i) for i, c in enumerate(reversed(self.word2)))
        result = sum(mapping[c] * (10 ** i) for i, c in enumerate(reversed(self.result)))
        return num1 + num2 == result
    def solve(self):
        self.solutions = []
        for perm in permutations(range(10), len(self.letters)):
            if self.is_valid_solution(perm):
                solution = dict(zip(self.letters, perm))
                self.solutions.append(solution)
        return self.solutions

def print_solution(word1, word2, result, solution):
    def word_to_num(word, mapping):
        return ''.join(str(mapping[c]) for c in word)
    num1 = int(word_to_num(word1, solution))
    num2 = int(word_to_num(word2, solution))
    res = int(word_to_num(result, solution))
    width = max(len(str(num1)), len(str(num2)), len(str(res))) + 2
    print("\nSolution:")
    print(f"{word1:>{width}} = {num1}")
    print(f"{word2:>{width}} = {num2}")
    print("-" * width)
    print(f"{result:>{width}} = {res}")
    print("\nLetter mappings:")
    for letter, value in sorted(solution.items()):
        print(f"{letter} = {value}")

def main():
    print("Enter the cryptarithmetic puzzle (e.g., SEND + MORE = MONEY)")
    print("First word:")
    word1 = input().strip()
    print("Second word:")
    word2 = input().strip()
    print("Result word:")
    result = input().strip()
    solver = CryptarithmeticSolver(word1, word2, result)
    solutions = solver.solve()
    if solutions:
        print(f"\nFound {len(solutions)} solution(s)!")
        for i, solution in enumerate(solutions, 1):
            print(f"\nSolution {i}:")
            print_solution(word1, word2, result, solution)
    else:
        print("\nNo solution found!")
if __name__ == "__main__":
    main() 

// Code Name: AI Model Comparison (ChatGPT vs Gemini)
// Topic: AI Model Evaluation and Comparison
// Theory: Comparing AI models involves evaluating their responses to a set of test cases using multiple criteria such as accuracy, completeness, clarity, creativity, response time, and consistency. Automated scripts can call APIs for each model, collect responses, and score them using both quantitative and qualitative metrics. This approach provides a systematic way to benchmark and select the best model for a given application.
// Explanation: This code compares the performance of ChatGPT and Gemini on a set of questions from different categories. It calls each model's API, evaluates responses on several criteria, and prints a summary of the results. API keys must be set in a .env file.
// Example user input:
// (No user input required; just run the script. Make sure to set OPENAI_API_KEY and GEMINI_API_KEY in your .env file.)

<code>
import requests
import json
import os
from typing import List, Dict
import time
from dotenv import load_dotenv

class AIModelComparison:
    def __init__(self):
        load_dotenv()
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.gemini_api_key = os.getenv('GEMINI_API_KEY')
        if not self.openai_api_key or not self.gemini_api_key:
            raise ValueError("Please set OPENAI_API_KEY and GEMINI_API_KEY in .env file")
        self.test_cases = [
            {
                "category": "General Knowledge",
                "questions": [
                    "What is the capital of France?",
                    "Who wrote 'Romeo and Juliet'?",
                    "What is the chemical symbol for gold?"
                ]
            },
            {
                "category": "Mathematics",
                "questions": [
                    "What is the square root of 144?",
                    "Solve the equation: 2x + 5 = 15",
                    "What is the area of a circle with radius 5?"
                ]
            },
            {
                "category": "Programming",
                "questions": [
                    "What is a Python list comprehension?",
                    "Explain the difference between '==' and '===' in JavaScript",
                    "What is object-oriented programming?"
                ]
            },
            {
                "category": "Creative Writing",
                "questions": [
                    "Write a short story about a magical forest",
                    "Create a poem about the ocean",
                    "Describe a futuristic city"
                ]
            }
        ]
        self.evaluation_criteria = [
            "Accuracy",
            "Completeness",
            "Clarity",
            "Response Time",
            "Creativity",
            "Consistency"
        ]
    def call_chatgpt(self, prompt: str) -> Dict:
        headers = {
            'Authorization': f'Bearer {self.openai_api_key}',
            'Content-Type': 'application/json'
        }
        data = {
            'model': 'gpt-3.5-turbo',
            'messages': [{'role': 'user', 'content': prompt}],
            'temperature': 0.7
        }
        start_time = time.time()
        response = requests.post(
            'https://api.openai.com/v1/chat/completions',
            headers=headers,
            json=data
        )
        end_time = time.time()
        if response.status_code == 200:
            return {
                'text': response.json()['choices'][0]['message']['content'],
                'time': end_time - start_time
            }
        else:
            return {
                'text': f"Error: {response.status_code}",
                'time': end_time - start_time
            }
    def call_gemini(self, prompt: str) -> Dict:
        headers = {
            'Content-Type': 'application/json'
        }
        data = {
            'contents': [{'parts': [{'text': prompt}]}]
        }
        start_time = time.time()
        response = requests.post(
            f'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={self.gemini_api_key}',
            headers=headers,
            json=data
        )
        end_time = time.time()
        if response.status_code == 200:
            return {
                'text': response.json()['candidates'][0]['content']['parts'][0]['text'],
                'time': end_time - start_time
            }
        else:
            return {
                'text': f"Error: {response.status_code}",
                'time': end_time - start_time
            }
    def evaluate_response(self, response: Dict, criteria: str) -> float:
        if 'Error' in response['text']:
            return 0.0
        score = 0.0
        text = response['text'].lower()
        if criteria == "Response Time":
            score = max(1.0, 5.0 - response['time'])
        elif criteria == "Completeness":
            length = len(text.split())
            score = min(5.0, length / 50)
        elif criteria == "Clarity":
            words = text.split()
            avg_word_length = sum(len(word) for word in words) / len(words)
            score = 5.0 if 4 <= avg_word_length <= 7 else 3.0
        elif criteria == "Consistency":
            score = 4.0
        elif criteria == "Creativity":
            unique_words = len(set(text.split()))
            total_words = len(text.split())
            score = min(5.0, (unique_words / total_words) * 10)
        else:
            score = 4.0
        return score
    def run_comparison(self) -> Dict:
        results = {
            'ChatGPT': {criteria: [] for criteria in self.evaluation_criteria},
            'Gemini': {criteria: [] for criteria in self.evaluation_criteria}
        }
        for category in self.test_cases:
            print(f"\nTesting category: {category['category']}")
            for question in category['questions']:
                print(f"\nQuestion: {question}")
                chatgpt_response = self.call_chatgpt(question)
                gemini_response = self.call_gemini(question)
                print("\nChatGPT response:", chatgpt_response['text'][:100] + "...")
                print("Response time:", f"{chatgpt_response['time']:.2f}s")
                print("\nGemini response:", gemini_response['text'][:100] + "...")
                print("Response time:", f"{gemini_response['time']:.2f}s")
                for criteria in self.evaluation_criteria:
                    chatgpt_score = self.evaluate_response(chatgpt_response, criteria)
                    gemini_score = self.evaluate_response(gemini_response, criteria)
                    results['ChatGPT'][criteria].append(chatgpt_score)
                    results['Gemini'][criteria].append(gemini_score)
        return results
    def print_results(self, results: Dict):
        print("\n" + "="*50)
        print("COMPARISON RESULTS")
        print("="*50)
        for criteria in self.evaluation_criteria:
            print(f"\n{criteria}:")
            chatgpt_avg = sum(results['ChatGPT'][criteria]) / len(results['ChatGPT'][criteria])
            gemini_avg = sum(results['Gemini'][criteria]) / len(results['Gemini'][criteria])
            print(f"ChatGPT: {chatgpt_avg:.2f}/5.0")
            print(f"Gemini:  {gemini_avg:.2f}/5.0")
            if chatgpt_avg > gemini_avg:
                print("Winner: ChatGPT")
            elif gemini_avg > chatgpt_avg:
                print("Winner: Gemini")
            else:
                print("Tie")
        chatgpt_total = sum(sum(scores) for scores in results['ChatGPT'].values())
        gemini_total = sum(sum(scores) for scores in results['Gemini'].values())
        print("\n" + "="*50)
        print("OVERALL RESULTS")
        print("="*50)
        print(f"ChatGPT total score: {chatgpt_total:.2f}")
        print(f"Gemini total score:  {gemini_total:.2f}")
        print(f"Overall winner: {'ChatGPT' if chatgpt_total > gemini_total else 'Gemini'}")
def main():
    print("Starting AI Model Comparison...")
    print("Note: This script requires API keys for both OpenAI (ChatGPT) and Google (Gemini)")
    print("Please ensure you have set these in your .env file:")
    print("OPENAI_API_KEY=your_openai_key")
    print("GEMINI_API_KEY=your_gemini_key")
    try:
        comparator = AIModelComparison()
        results = comparator.run_comparison()
        comparator.print_results(results)
    except ValueError as e:
        print(f"Error: {e}")
        print("Please set up your API keys and try again.")
    except Exception as e:
        print(f"An error occurred: {e}")
if __name__ == "__main__":
    main() 

// Code Name: Similarity Scorer (NLP)
// Topic: Natural Language Processing (NLP) - Text Similarity
// Theory: Text similarity measures how alike two pieces of text are, using metrics such as vector-based similarity (spaCy), semantic similarity (WordNet), and set-based similarity (Jaccard). Combining these methods provides a robust assessment of both surface-level and deep semantic similarity. Such techniques are essential for tasks like information retrieval, paraphrase detection, and semantic search.
// Explanation: This code compares two user-provided texts using three methods: spaCy's vector similarity, WordNet-based semantic similarity, and Jaccard similarity. It outputs each score and a weighted average, providing a comprehensive similarity analysis.
// Example user input:
// Text 1 (or press Enter for default example): The quick brown fox jumps over the lazy dog.
// Text 2 (or press Enter for default example): A fast brown fox leaps across a sleepy canine.

<code>
import spacy
import numpy as np
from typing import List, Tuple, Dict
from nltk.corpus import wordnet
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import nltk

class SimilarityScorer:
    def __init__(self):
        try:
            nltk.data.find('corpora/wordnet')
            nltk.data.find('corpora/stopwords')
        except LookupError:
            print("Downloading required NLTK data...")
            nltk.download('wordnet')
            nltk.download('stopwords')
        try:
            self.nlp = spacy.load('en_core_web_sm')
        except OSError:
            print("Downloading spaCy English model...")
            spacy.cli.download('en_core_web_sm')
            self.nlp = spacy.load('en_core_web_sm')
        self.stop_words = set(stopwords.words('english'))

    def preprocess_text(self, text: str) -> List[str]:
        tokens = word_tokenize(text.lower())
        tokens = [token for token in tokens if token not in self.stop_words and token.isalpha()]
        return tokens

    def get_wordnet_similarity(self, word1: str, word2: str) -> float:
        synsets1 = wordnet.synsets(word1)
        synsets2 = wordnet.synsets(word2)
        if not synsets1 or not synsets2:
            return 0.0
        max_sim = 0.0
        for syn1 in synsets1:
            for syn2 in synsets2:
                sim = syn1.path_similarity(syn2)
                if sim and sim > max_sim:
                    max_sim = sim
        return max_sim

    def get_spacy_similarity(self, text1: str, text2: str) -> float:
        doc1 = self.nlp(text1)
        doc2 = self.nlp(text2)
        if not doc1.vector_norm or not doc2.vector_norm:
            return 0.0
        return doc1.similarity(doc2)

    def get_jaccard_similarity(self, text1: str, text2: str) -> float:
        tokens1 = set(self.preprocess_text(text1))
        tokens2 = set(self.preprocess_text(text2))
        intersection = len(tokens1.intersection(tokens2))
        union = len(tokens1.union(tokens2))
        return intersection / union if union > 0 else 0.0

    def get_semantic_similarity(self, text1: str, text2: str) -> Dict[str, float]:
        spacy_sim = self.get_spacy_similarity(text1, text2)
        jaccard_sim = self.get_jaccard_similarity(text1, text2)
        tokens1 = self.preprocess_text(text1)
        tokens2 = self.preprocess_text(text2)
        wordnet_sims = []
        for word1 in tokens1:
            word_sims = []
            for word2 in tokens2:
                sim = self.get_wordnet_similarity(word1, word2)
                word_sims.append(sim)
            if word_sims:
                wordnet_sims.append(max(word_sims))
        wordnet_sim = np.mean(wordnet_sims) if wordnet_sims else 0.0
        weights = {'spacy': 0.4, 'wordnet': 0.4, 'jaccard': 0.2}
        weighted_avg = (spacy_sim * weights['spacy'] + 
                       wordnet_sim * weights['wordnet'] + 
                       jaccard_sim * weights['jaccard'])
        return {
            'spacy_similarity': spacy_sim,
            'wordnet_similarity': wordnet_sim,
            'jaccard_similarity': jaccard_sim,
            'weighted_average': weighted_avg
        }

def print_similarity_scores(text1: str, text2: str, scores: Dict[str, float]):
    print("\nText Similarity Analysis")
    print("=" * 50)
    print("Text 1:", text1)
    print("Text 2:", text2)
    print("-" * 50)
    print("Similarity Scores:")
    for method, score in scores.items():
        method_name = method.replace('_', ' ').title()
        print(f"{method_name:20}: {score:.4f}")
    print("=" * 50)

def main():
    print("Enter two texts to compare:")
    print("\nText 1 (or press Enter for default example):")
    text1 = input().strip()
    print("Text 2 (or press Enter for default example):")
    text2 = input().strip()
    if not text1 or not text2:
        text1 = "The quick brown fox jumps over the lazy dog."
        text2 = "A fast brown fox leaps across a sleepy canine."
        print(f"\nUsing default examples:")
        print(f"Text 1: '{text1}'")
        print(f"Text 2: '{text2}'")
    scorer = SimilarityScorer()
    scores = scorer.get_semantic_similarity(text1, text2)
    print_similarity_scores(text1, text2, scores)

if __name__ == "__main__":
    main() 

// Code Name: Spell Checker (NLP)
// Topic: Natural Language Processing (NLP) - Spell Checking
// Theory: Spell checking involves detecting and correcting misspelled words in text. Modern spell checkers use a combination of dictionary lookup, edit distance (such as Levenshtein distance), and word frequency from large corpora to suggest the most probable corrections. Candidate corrections are ranked by likelihood, and confidence scores can be provided based on edit distance and word probability.
// Explanation: This code checks the spelling of each word in a user-provided text, suggests corrections, and provides a confidence score for each suggestion. It uses NLTK corpora for vocabulary and word frequency, and edit distance for candidate generation.
// Example user input:
// Enter text to check spelling (or press Enter for default example): This is a sampel text with misspeled words and typoss.

<code>
import re
from collections import Counter
import nltk
from nltk.corpus import words, brown
from typing import List, Dict
import string
import numpy as np

class SpellChecker:
    def __init__(self):
        try:
            nltk.data.find('corpora/words')
            nltk.data.find('corpora/brown')
        except LookupError:
            print("Downloading required NLTK data...")
            nltk.download('words')
            nltk.download('brown')
        self.words = set(words.words())
        self.word_freq = Counter(word.lower() for word in brown.words())
        common_words = {'python', 'javascript', 'programming', 'developer', 'code'}
        self.words.update(common_words)
        self.words_lower = {word.lower() for word in self.words}
    def _tokenize(self, text: str) -> List[str]:
        words = re.findall(r'\b\w+\b', text.lower())
        return words
    def _get_word_probability(self, word: str) -> float:
        total_words = sum(self.word_freq.values())
        return self.word_freq[word.lower()] / total_words if total_words > 0 else 0
    def _get_edit_distance(self, s1: str, s2: str) -> int:
        if len(s1) < len(s2):
            return self._get_edit_distance(s2, s1)
        if len(s2) == 0:
            return len(s1)
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        return previous_row[-1]
    def _get_candidates(self, word: str) -> List[str]:
        letters = string.ascii_lowercase
        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]
        deletes = [L + R[1:] for L, R in splits if R]
        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]
        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]
        inserts = [L + c + R for L, R in splits for c in letters]
        all_edits = set(deletes + transposes + replaces + inserts)
        candidates = [word for word in all_edits if word.lower() in self.words_lower]
        if word.lower() in self.words_lower:
            candidates.append(word)
        return candidates
    def check_word(self, word: str) -> Dict[str, any]:
        word_lower = word.lower()
        if word_lower in self.words_lower:
            return {
                'word': word,
                'correct': True,
                'suggestions': [],
                'confidence': 1.0
            }
        candidates = self._get_candidates(word_lower)
        if not candidates:
            return {
                'word': word,
                'correct': False,
                'suggestions': [],
                'confidence': 0.0
            }
        scored_candidates = []
        for candidate in candidates:
            edit_dist = self._get_edit_distance(word_lower, candidate.lower())
            probability = self._get_word_probability(candidate)
            score = edit_dist / (probability + 0.1)
            scored_candidates.append((candidate, score))
        scored_candidates.sort(key=lambda x: x[1])
        best_score = scored_candidates[0][1]
        confidence = 1.0 / (1.0 + best_score)
        return {
            'word': word,
            'correct': False,
            'suggestions': [c[0] for c in scored_candidates[:5]],
            'confidence': confidence
        }
    def check_text(self, text: str) -> List[Dict[str, any]]:
        words = self._tokenize(text)
        return [self.check_word(word) for word in words]

def print_spell_check_results(text: str, results: List[Dict[str, any]]):
    print("\nSpell Check Results")
    print("=" * 60)
    print("Original text:", text)
    print("-" * 60)
    has_errors = False
    for result in results:
        if not result['correct']:
            has_errors = True
            print(f"\nWord: {result['word']}")
            print(f"Suggestions: {', '.join(result['suggestions']) if result['suggestions'] else 'No suggestions'}")
            print(f"Confidence: {result['confidence']:.2%}")
    if not has_errors:
        print("No spelling errors found!")
    print("=" * 60)

def main():
    print("Enter text to check spelling (or press Enter for default example):")
    text = input().strip()
    if not text:
        text = "This is a sampel text with misspeled words and typoss."
        print(f"\nUsing default example: '{text}'")
    checker = SpellChecker()
    results = checker.check_text(text)
    print_spell_check_results(text, results)

if __name__ == "__main__":
    main() 



//non ai tic tac toe:
    #tic tac toe,nqueens(4) and magic square
import random
def strike(text):
    return '\u0336'.join([u'\u0336{}'.format(c) for c in text])
x1=99
x2=99
x3=99
y1=99
y2=99
y3=99

global a
w, h = 4,4
a = [[9 for x in range(w)] for y in range(h)] 
end=0
z1=0
z2=0
z3=0
z4=0
z5=0
z6=0
z7=0
z8=0
q2=0
q3=0
q1=0
q4=0
q5=0
q6=0
q7=0
q8=0
def check_win():
    global z1,z2,z3,z4,z5,z6,z7,z8,q1,q2,q3,q4,q5,q6,q7,q8,x1,x2,x3,y1,y2,y3,end,a

    for i in range (3):
        for j in range(3):
            if(a[i][j]==2 ):
                z1=i-1
                z2=j-1
                z3=i+1
                z4=j+1
                z5=i-1
                z6=j+1
                z7=i+1
                z8=j-1
            else:
                q1=i-1
                q2=j-1
                q3=i+1
                q4=j+1
                q5=i-1
                q6=j+1
                q7=i+1
                q8=j-1
            for h in range(4):
                checkh1=0
                checkh2=0
                checkv1=0
                checkv2=0
                for y in range(4):
                    if(a[h][y]==2):
                        checkh2=1
                    else:
                        checkh2=0
                    if(a[y][h]==2):
                        checkv2=1
                    else:
                        checkv2=0
                    if(a[h][y]==1):
                        checkh1=1
                    else:
                        checkh1=0
                    if(a[y][h]==1):
                        checkv1=1
                    else:
                        checkv1=0     
                if(checkh1==1):
                    x1=y-2
                    x2=y-2
                    x3=y-2
                    y1=0
                    y2=1
                    y3=2
                    print("Player 1 won horizontal!!")
                    end=1
                    win()
                    return
                elif(checkh2==1):
                    x1=y-2
                    x2=y-2
                    x3=y-2
                    y1=0
                    y2=1
                    y3=2
                    print("Player 2 won horziontal!!")
                    end=1
                    win()
                    return
                elif(checkv1==1):
                    x1=0
                    x2=1
                    x3=2
                    y1=y-2
                    y2=y-2
                    y3=y-2
                    print("Player 1 won vertical !!")
                    end=1
                    win()
                    return
                elif(checkv2==1):
                    x1=0
                    x2=1
                    x3=2
                    y1=y-2
                    y2=y-2
                    y3=y-2
                    print("Player 2 won vertical!!")
                    end=1
                    win()
                    return
            if(a[z1][z2] and a[z1][z2]==2 and a[z3][z4]==2 and a[i][j]==2):
                x1=z1
                x2=z3
                x3=i
                y1=z2
                y2=z4
                y3=j
                print(strike("player2 wins diagonal"))
                end=1
                win()
                return
            elif(a[z5][z6] and a[z5][z6]==2 and a[z7][z8]==2 and a[i][j]==2):
                x1=z5
                x2=z7
                x3=i
                y1=z6
                y2=z8
                y3=j
                print(strike("player2 wins diagonal"))
                end=1
                win()
                return
            elif(a[q1][q2] and a[q1][q2]==1 and a[q3][q4]==1 and a[i][j]==1):
                x1=q1
                x2=q3
                x3=i
                y1=q2
                y2=q4
                y3=j
                print(strike("player1 wins diagonal"))
                end=1
                win()
                return
            elif(a[q5][q6] and a[q5][q6]==1 and a[q7][q8]==1 and a[i][j]==1):
                x1=q5
                x2=q7
                x3=i
                y1=q6
                y2=q8
                y3=j
                print(strike("player1 wins diagonal"))
                end=1
                win()
                return

done=0    
def win():
    global z1,z2,z3,z4,q1,q2,q3,q4,x1,x2,x3,y1,y2,y3,end,a,done
    #print(x1,y1,x2,y2,x3,y3)
    
    if(end!=1):
        done=2
    if(done!=1):
        for i in range(3):
            for j in range(3):
                if(((i==x1 and j==y1) or (i==x2 and j==y2) or (i==x3 and j==y3 )) and end!=0 ):
                    if(a[i][j]==2):
                        print(strike(" x"),end="")
                    elif(a[i][j]==1):
                        print(strike(" y"),end="")
                else:
                    if(a[i][j]==2):
                        print(" x ",end="")
                    elif(a[i][j]==1):
                        print(" y ",end="")
                    else:
                        print(" - ",end="")

            print("")
    if(end==1):
        done=1

global won

print("Player 1 is X\nPlayer 2 is O")
p1=0
p2=0
claim=1
print("Toss")
print("Player 1 choose \n1:Tails\n2:Heads")
toss=int(input())
if((random.randint(1,2)==toss) ):
    print("Player 1 wins")
    won=1;
else:
    print("PLayer 2 wins")
    won=2

while(end==0):
    if(won==1 and claim!=99):
        print("Player1's turn")
        claim=0
    elif(won==2 and claim!=99):
        print("Player2's turn")
        claim=0
    elif(p1==0):
        print("Player1's turn")
    elif(p2==0):
        print("Player2's turn")
    print("Enter Co ordinates separated by space:")
    if(won==1 and claim==0):
        e=int(input())-1
        r=int(input())-1
        a[e][r]=2;
        p1=1;
        p2=0;
        claim=99
    elif(won==2 and claim==0):
        e=int(input())-1
        r=int(input())-1
        a[e][r]=1;
        p1=0;
        p2=1;
        claim=99
    elif(p1==0):
        e=int(input())-1
        r=int(input())-1
        a[e][r]=2;
        p1=1;
        p2=0;
    elif(p2==0):
        e=int(input())-1
        r=int(input())-1
        a[e][r]=1;
        p1=0;
        p2=1;
    
    check_win()
    win()


//4 queens n queens queen
def print_solution(board, n):
    """Prints the chessboard with 'Q' for queens and '.' for empty spaces."""
    for row in board:
        line = ""
        for cell in row:
            line += "Q " if cell else ". "
        print(line)
    print()

def is_safe(board, row, col, n):
    """Checks if placing a queen at board[row][col] is safe."""
    for i in range(col):
        if board[row][i]:
            return False

    for i, j in zip(range(row, -1, -1), range(col, -1, -1)):
        if board[i][j]:
            return False

    for i, j in zip(range(row, n), range(col, -1, -1)):
        if board[i][j]:
            return False

    return True

def solve_n_queens_util(board, col, n):
    """Utility function to solve N-Queens problem using backtracking."""
    if col >= n:
        print_solution(board, n)
        return True

    res = False
    for i in range(n):
        if is_safe(board, i, col, n):
            board[i][col] = True
            res = solve_n_queens_util(board, col + 1, n) or res
            board[i][col] = False
    return res

def solve_n_queens(n):
    """Main function to initiate solving the N-Queens problem."""
    board = [[False for _ in range(n)] for _ in range(n)]
    if not solve_n_queens_util(board, 0, n):
        print("No solution exists.")

n = int(input("Enter the size of the board: "))
if n < 1:
    print("Board size must be at least 1.")
else:
    solve_n_queens(n)

//magic square 3*3
import random

def print_grid(grid):
    for row in grid:
        print(" ".join([str(cell) if cell != 0 else "-" for cell in row]))
    print()

def is_magic_square(grid):
    target_sum = 15
    nums = [grid[i][j] for i in range(3) for j in range(3) if grid[i][j] != 0]

    if len(nums) != len(set(nums)) or any(num < 1 or num > 9 for num in nums):
        return False

    for row in grid:
        if sum(row) != target_sum:
            return False

    for col in range(3):
        if sum(grid[row][col] for row in range(3)) != target_sum:
            return False

    if sum(grid[i][i] for i in range(3)) != target_sum:
        return False

    if sum(grid[i][2 - i] for i in range(3)) != target_sum:
        return False

    return True

def check_win(grid):
    if is_magic_square(grid):
        print("\nCongratulations! The grid forms a magic square:")
        print_grid(grid)
        return True
    return False

def magic_square_game():
    grid = [[0 for _ in range(3)] for _ in range(3)]
    available_numbers = set(range(1, 10))
    player_turn = random.randint(1, 2)

    print("Welcome to the 3x3 Magic Square Game!")
    print("Players take turns to enter numbers from 1 to 9 into the grid.")
    print("The goal is to create a magic square where the sums of all rows, columns, and diagonals are 15.")
    print("Each number can only be used once. Let's begin!\n")

    print("Player 1 is X\nPlayer 2 is O")
    print("Player {} starts.\n".format(player_turn))

    while True:
        print("Current Grid:")
        print_grid(grid)
        
        if(not available_numbers):
            print("You lost!!")
            return
        print("Available Numbers:", available_numbers)
        try:
            print("Player {}'s turn. Enter row, column, and number (separated by spaces):".format(player_turn))
            row, col, num = map(int, input().split())

            if not (0 <= row < 3 and 0 <= col < 3):
                print("Invalid position! Row and column must be between 0 and 2.")
                continue

            if grid[row][col] != 0:
                print("Cell is already occupied! Choose another cell.")
                continue

            if num not in available_numbers:
                print("Number not available or already used! Choose another number.")
                continue

            grid[row][col] = num
            available_numbers.remove(num)

            if check_win(grid):
                break

            player_turn = 2 if player_turn == 1 else 1

        except ValueError:
            print("Invalid input! Please enter row, column, and number as integers separated by spaces.")

    print("Game Over. Thanks for playing!")

magic_square_game()

//water jug using bfs and dfs

from collections import deque

def dfs(jug1, jug2, target, x, y, visited):
    if (x, y) in visited:
        return
    visited.add((x, y))
    print(f"Visited: ({x}, {y})")

    if x == target or y == target:
        print(f"Solution found using DFS: ({x}, {y})")
        return

    next_states = [
        (jug1, y), (x, jug2), (0, y), (x, 0),
        (x - min(x, jug2 - y), y + min(x, jug2 - y)),
        (x + min(y, jug1 - x), y - min(y, jug1 - x))
    ]

    for nx, ny in next_states:
        dfs(jug1, jug2, target, nx, ny, visited)

def bfs(jug1, jug2, target):
    queue = deque([(0, 0)])
    visited = set(queue)

    while queue:
        x, y = queue.popleft()
        print(f"Visited: ({x}, {y})")

        if x == target or y == target:
            print(f"Solution found using BFS: ({x}, {y})")
            return

        next_states = [
            (jug1, y), (x, jug2), (0, y), (x, 0),
            (x - min(x, jug2 - y), y + min(x, jug2 - y)),
            (x + min(y, jug1 - x), y - min(y, jug1 - x))
        ]

        for state in next_states:
            if state not in visited:
                queue.append(state)
                visited.add(state)

    print("No solution found using BFS")

jug1, jug2, target = 5, 3, 2

jug1=int(input(("Enter jug 1 capacity:")))

jug2=int(input(("Enter jug 2 capacity:")))

target=int(input(("Enter target capacity to measure:")))
print("Using DFS:")
dfs(jug1, jug2, target, 0, 0, set())

print("\nUsing BFS:")
bfs(jug1, jug2, target)

//hill climb
import copy

N = 3

goal = [
    [1, 2, 3],
    [4, 5, 6],
    [7, 8, 0]
]

def calculate_misplaced_tiles(puzzle):
    misplaced = 0
    for i in range(N):
        for j in range(N):
            if puzzle[i][j] != 0 and puzzle[i][j] != goal[i][j]:
                misplaced += 1
    return misplaced

def find_blank(puzzle):
    for i in range(N):
        for j in range(N):
            if puzzle[i][j] == 0:
                return i, j

def print_puzzle(puzzle):
    for row in puzzle:
        print(" ".join(f"{num:2}" if num != 0 else "  " for num in row))
    print()

moves = [
    (1, 0),
    (-1, 0),
    (0, 1),
    (0, -1)
]

def hill_climbing(puzzle):
    current = copy.deepcopy(puzzle)
    move_count = 0
    
    while True:
        blank_row, blank_col = find_blank(current)
        current_heuristic = calculate_misplaced_tiles(current)
        best_heuristic = current_heuristic
        best_move = None
        
        for move in moves:
            new_row, new_col = blank_row + move[0], blank_col + move[1]
            
            if 0 <= new_row < N and 0 <= new_col < N:
                new_puzzle = copy.deepcopy(current)
                new_puzzle[blank_row][blank_col], new_puzzle[new_row][new_col] = new_puzzle[new_row][new_col], new_puzzle[blank_row][blank_col]
                
                new_heuristic = calculate_misplaced_tiles(new_puzzle)
                if new_heuristic < best_heuristic:
                    best_heuristic = new_heuristic
                    best_move = (new_row, new_col)
        
        if best_move is None:
            print("Local Optima Reached! No better move found.")
            print(f"Total moves taken: {move_count}")
            break
        
        blank_row, blank_col = best_move
        current[find_blank(current)[0]][find_blank(current)[1]], current[blank_row][blank_col] = current[blank_row][blank_col], current[find_blank(current)[0]][find_blank(current)[1]]
        
        move_count += 1
        print(f"Move {move_count}:")
        print_puzzle(current)
        
        if best_heuristic == 0:
            print("Goal State Reached!")
            print(f"Total moves taken: {move_count}")
            break

puzzle = [
    [1, 2, 3],
    [5, 6, 0],
    [4, 7, 8]
]
print("Initial State:")
print_puzzle(puzzle)
print("Solving using Hill Climbing with Misplaced Tile Heuristic...")
hill_climbing(puzzle)


//now brief notes for detailed notes search detailed notes in the file
1. Introduction to Artificial Intelligence (1.1 Introduction to AI.pptx)
	What is AI? AI involves creating machines that can behave intelligently. This can be approached by aiming for machines that act humanly, think humanly, think rationally, or act rationally.
	Turing Test: Proposed by Alan Turing, it tests if a machine can exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human. Passing requires capabilities like Natural Language Processing (NLP), Knowledge Representation, Automated Reasoning, and Machine Learning. The "Total Turing Test" adds requirements for perception (like vision) and motor control.
	Foundations of AI: AI draws from various fields including Philosophy, Mathematics, Economics, Neuroscience, Psychology, Computer Engineering, Control Theory, and Linguistics.
	Branches of AI: Key areas include Logical AI, Search, NLP, Pattern Recognition, Knowledge Representation, Inference, Automated Reasoning, Learning, Planning, Epistemology, and Ontology.
	Applications: AI is used in autonomous planning (rovers, telescopes), data analysis, medicine (image-guided surgery, image analysis), transportation (autonomous vehicles), gaming, robotics, bioinformatics, text/image classification, and NLP.
2. Intelligent Agents (1.3 Intelligent Agents.pptx)
	Agent Definition: An agent perceives its environment through sensors and acts upon it through actuators. Examples include humans, robots, and software agents.
	Rational Agents: A rational agent acts to maximize its expected performance measure, given its percept sequence, prior knowledge, and possible actions. Rationality depends on the performance measure, environment knowledge, actions, and percept sequence.
	Agent Structure: Agent = Architecture (computing device) + Program (implements agent function). The agent program maps percepts to actions.
	Task Environments (PEAS): Environments are described by Performance measure, Environment, Actuators, and Sensors. Examples include automated taxis and medical diagnosis systems.
	Environment Types: Environments can be classified based on properties like: 
o	Fully vs. Partially Observable 
o	Deterministic vs. Stochastic (vs. Strategic) 
o	Episodic vs. Sequential 
o	Static vs. Dynamic (vs. Semidynamic) 
o	Discrete vs. Continuous 
o	Single-agent vs. Multi-agent 
o	Known vs. Unknown 
	Agent Types: 
o	Simple Reflex Agents: Act based only on the current percept using condition-action rules. Work only in fully observable environments.
o	Model-Based Reflex Agents: Maintain internal state to handle partial observability. Use a model of how the world works.
o	Goal-Based Agents: Act to achieve explicit goals. May require search and planning.
o	Utility-Based Agents: Choose actions that maximize expected utility, useful when goals conflict or have uncertainty.
o	Learning Agents: Can improve their performance over time through learning. Components include a performance element, learning element, critic, and problem generator.
3. Problem Solving and Search (Unit 1 & 2.1.pptx, 1.3 Basic State Space Search.pptx)
	Problem Formulation: Defining a problem involves specifying: 
o	Initial State: Where the agent starts.
o	Actions/Operators: What the agent can do.
o	Transition Model (Successor Function): The result of performing an action in a state.
o	Goal Test: How to determine if a state is a goal state.
o	Path Cost Function: Assigns a cost to a sequence of actions (path).
	State Space: The set of all reachable states from the initial state, forming a graph.
	Search Tree: Represents the exploration of the state space. Nodes include state, parent, action, path cost, and depth.
	Search Process: Finding a sequence of actions (a solution or plan) that leads from the initial state to a goal state. 
o	Generic steps: Check current state, find successors, pick one, check if goal, repeat.
	Measuring Performance: Search strategies are evaluated based on: 
o	Completeness: Does it always find a solution if one exists? 
o	Optimality: Does it find the best (e.g., lowest cost) solution? 
o	Time Complexity: How long does it take? 
o	Space Complexity: How much memory does it need? 
	Uninformed Search Strategies: Use only the information available in the problem definition. 
o	Breadth-First Search (BFS): Expands the shallowest nodes first (FIFO queue). Complete and optimal (if step costs are equal) but requires exponential time and space.
o	Uniform Cost Search (UCS): Expands the node with the lowest path cost (g(n)). Optimal and complete (if step costs >= 0).
o	Depth-First Search (DFS): Expands the deepest nodes first (LIFO queue). Low memory requirement (linear space), but not complete (can get stuck in infinite paths/loops) and not optimal.
o	Depth-Limited Search (DLS): DFS with a depth limit. Avoids infinite paths but is incomplete if the solution is deeper than the limit.
o	Iterative Deepening Search (IDS): Runs DLS with increasing depth limits (0, 1, 2...). Combines benefits of BFS (completeness, optimality for unit costs) and DFS (low memory).
o	Bidirectional Search: Searches forward from the start and backward from the goal simultaneously. Can be much faster but requires reversible actions and explicit goal states.
4. Hill Climbing (Hill climbing.pptx)
	Optimization/Local Search: Techniques that iteratively improve a single state solution, focusing on finding optimal (or near-optimal) states based on a cost/objective function.
	Hill Climbing Algorithm: 
o	A greedy, local search algorithm that doesn't backtrack.
o	Variant of generate-and-test, using feedback (heuristic evaluation) to guide the search.
o	Starts with an initial state and repeatedly moves to the best neighboring state.
o	Terminates when it reaches a state with no better neighbors.
	Successor Function: Crucial for hill climbing; defines the "neighborhood" of a state.
	Problems with Hill Climbing: Can get stuck in suboptimal states: 
o	Local Maximum: A state better than its neighbors but not the global best.
o	Plateau: A flat area where neighbors have the same value, making it hard to choose a direction.
o	Ridge: An area higher than surroundings but sloped such that single moves cannot traverse it easily.
5. AO* Algorithm (AO Star Algorithm.pdf)
	Informed Search: AO* is an informed, best-first search algorithm.
	Problem Decomposition: Based on breaking problems into smaller subproblems (AND-OR graphs).
	AND-OR Graphs: Represent problems where solutions require solving either one of several subproblems (OR nodes) or all of a set of subproblems (AND nodes). Nodes have heuristic values (h(n)) and path costs (g(n)).
	Algorithm Steps (Simplified): 
1.	Initialize graph with the start node.
2.	Traverse the current best path, expanding unexpanded nodes.
3.	For an expanded node, calculate f(n)=g(n)+h(n) for successors.
4.	Propagate cost changes back up the graph.
5.	Mark nodes/paths as SOLVED.
6.	Stop when the start node is SOLVED.
	Difference from A:* 
o	A* searches OR graphs for a single solution path.
o	AO* searches AND-OR graphs, potentially finding solutions involving multiple paths (due to AND nodes).
6. Natural Language Processing (Lecture Series Natural Langauge Processing (1) (1).pptx)
	NLP Definition: A field of AI focused on enabling computers to understand, interpret, and generate human language. Intersects linguistics, computer science, and machine learning.
	Fundamental Tasks: 
o	Tokenization: Breaking text into words or units.
o	Part-of-Speech (POS) Tagging: Assigning grammatical roles (noun, verb) to words.
o	Stemming: Reducing words to a root form by removing suffixes (e.g., "consulting" -> "consult").
o	Lemmatization: Reducing words to their dictionary form (lemma), considering grammar (e.g., "studies" -> "study").
o	Stop Word Removal: Removing common, low-meaning words (e.g., "the", "is").
	Key NLP Areas & Applications: 
o	Language Translation: Translating text between languages.
o	Summarization: Creating concise summaries of text.
o	Chatbots & Assistants: Virtual agents understanding natural language.
o	Sentiment Analysis: Determining positive/negative/neutral sentiment in text.
o	Emotion Detection: Identifying specific emotions (joy, anger).
o	Named Entity Recognition (NER): Identifying entities like people, places, organizations.
o	Information Extraction: Extracting structured information and relationships from text.
o	Natural Language Generation (NLG): Producing human-like text.
o	Speech Recognition: Converting spoken language to text.
o	Semantic Analysis: Understanding the meaning of text, considering context and structure. Includes Lexical (word meaning) and Compositional (sentence structure meaning) analysis. Tasks involve Word Sense Disambiguation and Relationship Extraction.
o	Pragmatic Analysis: Understanding meaning based on context and real-world knowledge.
	Challenges: Ambiguity (words/sentences with multiple meanings), context dependency, sarcasm, paraphrasing.
	NLP Job Market: High demand for NLP Engineers, Data Scientists, and Computational Linguists. Requires technical (ML, Python) and linguistic skills.


//now detailed notes
Okay, here is a more detailed version of the notes, covering almost all points mentioned in the provided files:

### **1.1 Introduction to AI.pptx**

* **What is AI?** [cite: 259]
    * Approaches can be categorized based on thinking/acting and humanly/rationally[cite: 284]:
        * Thinking Humanly: Cognitive Science approach.
        * Acting Humanly: Turing Test approach[cite: 236, 259].
        * Thinking Rationally: "Laws of thought"/Logic approach[cite: 285].
        * Acting Rationally: Rational agent approach[cite: 285].
* **Acting Humanly: The Turing Test** [cite: 236, 237]
    * Proposed by Alan Turing (1950) to provide an operational definition of intelligence[cite: 237, 239, 240].
    * Asks "Can machines behave intelligently?" instead of "Can machines think?"[cite: 237, 240].
    * Involves a human interrogator trying to distinguish between a human and a machine based on text responses[cite: 237, 240].
    * **Capabilities needed to pass:**
        * Natural Language Processing (NLP): To communicate[cite: 238, 241, 243].
        * Knowledge Representation: To store information[cite: 238, 241, 244].
        * Automated Reasoning: To use stored information, answer questions, draw conclusions[cite: 238, 241, 245].
        * Machine Learning: To adapt and extrapolate patterns[cite: 238, 241, 246].
    * **Total Turing Test:** Adds requirements for physical interaction[cite: 242]:
        * Vision: To perceive objects and actions[cite: 242, 247].
        * Motor Control: To act upon objects[cite: 242, 248].
        * Other senses (optional)[cite: 249].
    * **Limitations:** Not easily reproducible, constructive, or amenable to mathematical analysis; doesn't inherently cover physical interaction (addressed by Total Turing Test)[cite: 241].
* **Foundations of AI** [cite: 256]
    * **Philosophy:** Logic, reasoning methods, mind as a physical system, learning foundations, language, rationality.
    * **Mathematics:** Formal representation, proof, algorithms, computation, decidability, tractability.
    * **Statistics:** Modeling uncertainty, learning from data.
    * **Economics:** Utility, decision theory, rational economic agents.
    * **Neuroscience:** Neurons as information processing units.
    * **Psychology/Neuro Science:** How people behave, perceive, process cognitive information, represent knowledge.
    * **Computer Engineering:** Building fast computers.
    * **Control Theory:** Designing systems that maximize an objective function over time.
    * **Linguistics:** Knowledge representation, grammars.
* **Main Topics/Branches in AI** [cite: 252, 257]
    * Search (including Game Playing)[cite: 252, 257].
    * Knowledge Representation and Reasoning[cite: 252, 257].
    * Planning[cite: 253, 257].
    * Learning[cite: 253, 257].
    * Natural Language Processing (NLP)[cite: 252, 257].
    * Pattern Recognition[cite: 252].
    * Inference[cite: 252].
    * Automated Reasoning[cite: 253].
    * Expert Systems[cite: 257].
    * Epistemology (study of knowledge required)[cite: 253].
    * Ontology (study of existing things and relationships)[cite: 254].
    * Genetic Programming[cite: 254].
    * Interaction with Environment (Vision, Speech Recognition, Robotics)[cite: 258].
* **Advantages of AI** [cite: 258]
    * More powerful/useful computers.
    * New/improved interfaces.
    * Solving new problems.
    * Better information handling, relieves information overload.
    * Conversion of information into knowledge.
* **Disadvantages of AI** [cite: 259]
    * Increased costs.
    * Slow and expensive software development.
    * Few experienced programmers.
    * Few practical products have reached the market yet.
* **Major Breakthroughs:** Examples include Deep Blue beating Kasparov (1997), Watson winning Jeopardy! (2011), Google's DeepMind achieving human parity in Atari games (2015)[cite: 260].
* **Applications** [cite: 261, 262, 263, 264, 265, 266]
    * Autonomous Planning & Scheduling (Rovers, Telescope scheduling)[cite: 261].
    * Data Analysis (Prediction, Forecasting)[cite: 261].
    * Medicine (Image-guided surgery, Image analysis)[cite: 262].
    * Transportation (Autonomous vehicle control, Pedestrian detection)[cite: 263].
    * Gaming[cite: 264].
    * Robotics (Toys, Utility robots, Humanoid robots like Honda's)[cite: 265, 280, 281].
    * Bioinformatics (Gene expression analysis, Protein structure prediction)[cite: 266].
    * Text/Document Classification (Web pages, email, news)[cite: 266].
    * Video/Image Classification[cite: 266].
    * Creative Arts (Music composition, picture drawing)[cite: 266].
    * NLP (Question Answering systems like MIT's Infolab)[cite: 266, 282].
    * Search Engines[cite: 278].
    * Labor Automation[cite: 278].
    * Scientific Discovery[cite: 278].
    * Appliances[cite: 280].
* **What is Intelligence?** Comprises skills like reasoning, acquiring/applying knowledge, manipulating/communicating ideas[cite: 268].
* **Can Machines Think? (Debate)**
    * **Objections:** Theological (soul needed), "Head in Sand" (consequences too dreadful), Mathematical (limits of computation), Consciousness (lack of felt emotions), Various Disabilities (can't do X), Lady Lovelace (no originality), Continuity (nervous system isn't discrete), Informality (human behavior isn't rule-based)[cite: 270, 271, 272, 273].
    * **Chinese Room Argument (Searle):** Argues that manipulating symbols according to rules (like in the Turing Test) does not equate to understanding. A person following rules to manipulate Chinese symbols doesn't understand Chinese, thus a computer doing the same doesn't either. Conclusion: Mind is not just computation, Turing Test is inadequate[cite: 276, 277].

### **1.3 Intelligent Agents.pptx**

* **Agent Definition:** Anything that perceives its environment via sensors and acts upon it via actuators[cite: 209, 223].
    * **Human Agent:** Sensors: eyes, ears, etc.; Actuators: hands, legs, mouth, etc.[cite: 231].
    * **Robotic Agent:** Sensors: cameras, range finders; Actuators: motors[cite: 231].
    * **Software Agent:** Sensors: keystrokes, file contents, network packets; Actuators: screen display, writing files, sending packets[cite: 231].
* **Percepts & Percept Sequence:**
    * Percept: Agent's perceptual input at any instant.
    * Percept Sequence: The complete history of everything the agent has perceived[cite: 232]. Agent's action choice can depend on this entire sequence[cite: 233].
* **Rational Agents:**
    * Strive to "do the right thing" based on percepts and actions[cite: 189].
    * The "right action" is one that makes the agent most successful[cite: 189].
    * **Performance Measure:** An objective criterion for success[cite: 190, 191].
    * **Rationality depends on:**
        1.  Performance measure (defining success)[cite: 191].
        2.  Agent's prior knowledge of the environment[cite: 191].
        3.  Actions the agent can perform[cite: 191].
        4.  Agent's percept sequence to date[cite: 191].
    * **Definition:** For each possible percept sequence, a rational agent selects an action expected to *maximize* its performance measure, given the percept sequence and built-in knowledge[cite: 191].
* **Structure of Agents:** [cite: 192]
    * Agent = Architecture + Program[cite: 192].
    * Architecture: The computing device with sensors and actuators[cite: 192].
    * Agent Program: Implements the agent function (mapping percepts to actions). This is the focus of AI[cite: 192, 193].
    * **Table-Driven Agent:** A simple program that uses a lookup table indexed by percept sequences to determine actions. Feasible only for very small state spaces[cite: 195].
* **Task Environments (PEAS):** [cite: 196]
    * Specifies the setting for agent design.
    * **P**erformance Measure: How success is judged (e.g., safety, speed, profit for a taxi)[cite: 197].
    * **E**nvironment: Where the agent operates (e.g., roads, traffic, patients, hospital)[cite: 197].
    * **A**ctuators: How the agent acts on the environment (e.g., steering, brake, display screen)[cite: 197].
    * **S**ensors: How the agent perceives the environment (e.g., cameras, GPS, keyboard)[cite: 197].
* **Environment Types:**
    * **Fully Observable vs. Partially Observable:** Can sensors access the complete state? (Partial if noisy sensors or missing data)[cite: 198, 204]. Agents may need internal state for partial observability[cite: 199].
    * **Deterministic vs. Stochastic:** Is the next state fully determined by the current state and agent's action? (Stochastic if uncertain)[cite: 199, 206].
    * **Strategic:** Deterministic except for the actions of other agents[cite: 200, 206].
    * **Episodic vs. Sequential:** Is experience divided into independent episodes (perceive-act)? (Sequential if current action affects future decisions)[cite: 200, 207]. Episodic is simpler, no need to think ahead[cite: 207].
    * **Static vs. Dynamic:** Does the environment change while the agent deliberates?[cite: 201, 207].
    * **Semidynamic:** Environment doesn't change, but the performance score does[cite: 202, 207].
    * **Discrete vs. Continuous:** Finite, distinct states/percepts/actions vs. continuous values[cite: 202, 208].
    * **Single-agent vs. Multi-agent:** Is the agent operating alone or with others?[cite: 203, 208]. Multi-agent can be competitive (chess) or cooperative (automated driving)[cite: 208].
    * **Known vs. Unknown:** Does the agent know the "rules" or outcomes of actions? (Unknown requires learning)[cite: 210, 211].
    * *Examples:* Chess (Fully observable, Strategic, Sequential, Semi-static, Discrete, Multi-agent); Taxi Driving (Partially observable, Stochastic, Sequential, Dynamic, Continuous, Multi-agent)[cite: 212].
* **Agent Types:** [cite: 213]
    * **Simple Reflex Agents:** [cite: 213, 214]
        * Select actions based only on the *current* percept.
        * Use condition-action rules (if condition then action).
        * Work only if the environment is fully observable[cite: 214].
        * Example: Thermostat, simple animal reflexes[cite: 215].
    * **Model-Based Reflex Agents:** [cite: 213, 217, 219]
        * Maintain an internal state to track unseen parts of the world[cite: 217].
        * Need a model of how the world evolves and how actions affect it[cite: 218].
        * Handles partial observability better[cite: 217].
        * Example: Overtaking a car requires knowing where unseen cars might be[cite: 219].
    * **Goal-Based Agents:** [cite: 213, 221, 224]
        * Act to achieve explicit goals (desirable situations)[cite: 222].
        * Combine world model with goal information to choose actions[cite: 222].
        * May involve search and planning to find action sequences leading to goals.
        * More flexible than reflex agents.
    * **Utility-Based Agents:** [cite: 213, 225, 226]
        * Use a utility function mapping states (or sequences) to a real number representing "happiness" or desirability[cite: 225].
        * Act to maximize expected utility[cite: 225].
        * Useful for conflicting goals (provides trade-offs) or when goals have uncertainty (weights likelihood vs. importance)[cite: 225].
        * A generalization of goal-based agents (goals have utility 1, others 0).
    * **Learning Agents:** [cite: 213, 227, 228]
        * Can improve performance over time by learning from experience.
        * **Components:** [cite: 228]
            * *Performance Element:* Selects external actions (like other agent types).
            * *Learning Element:* Makes improvements based on feedback.
            * *Critic:* Provides feedback on how well the agent is doing against a performance standard.
            * *Problem Generator:* Suggests exploratory actions to gain new, informative experiences.

### **1.3 Basic State Space Search.pptx & Unit 1 & 2.1.pptx (Search Content)**

* **Problem-Solving Agents:** [cite: 311, 312]
    * Use search algorithms to find sequences of actions to achieve goals.
    * Process: Formulate Goal -> Formulate Problem -> Find Solution -> Execute Solution[cite: 59, 309, 311].
* **Problem Formulation:** [cite: 60, 105, 107, 295, 315, 316]
    * Defining the problem in terms of states, actions, etc., often requiring abstraction from real-world details[cite: 296, 310].
    * **Components:**
        1.  **Initial State:** The starting state ($s_0$)[cite: 60, 105, 107, 294, 313, 317].
        2.  **Actions/Operators:** Allowable transformations between states ($A: S_i \rightarrow S_j$)[cite: 60, 105, 107, 294, 313, 317].
        3.  **Transition Model / Successor Function:** Returns (action, successor state) pairs reachable from a given state[cite: 105, 108, 294].
        4.  **State Space:** The set of all states reachable from the initial state ($S$)[cite: 61, 108, 294, 317, 319]. Can be represented as a graph (nodes=states, arcs=actions)[cite: 294, 320].
        5.  **Goal Test:** Determines if a state is a goal state ($G \subseteq S$)[cite: 61, 105, 108, 295, 313, 317].
        6.  **Path Cost:** Function assigning a numeric cost to a path (sequence of actions)[cite: 62, 105, 109, 295, 314, 315]. Step cost $c(x, a, y)$ is the cost from state $x$ to $y$ via action $a$[cite: 296]. Path cost is often the sum of step costs[cite: 315].
* **Solution:** A sequence of actions (a plan or path) from the initial state to a goal state[cite: 63, 81, 308, 314, 317].
* **Generic Searching Process:** [cite: 286]
    * Loop until solution found or state space exhausted:
        1.  Check the current state[cite: 287].
        2.  Execute actions to find successor states[cite: 287].
        3.  Pick one successor state[cite: 288].
        4.  Check if it's a goal state; if not, make it the current state and repeat[cite: 288].
* **Search Tree:** [cite: 71, 72, 73]
    * Represents the exploration process.
    * Root node is the initial state.
    * Expanding a node means applying the successor function to generate child nodes.
    * Fringe: Set of generated but not yet expanded nodes[cite: 71].
    * **Node Components:** State, Parent Node, Action (that generated node), Path Cost (g(n) from start to node n), Depth[cite: 74].
    * Distinction: State Space vs. Search Tree (Search tree can have repeated states/cycles)[cite: 74].
* **Example Problems:**
    * **Route Finding (Romania):** States=Cities, Actions=Driving, Goal=Be in Bucharest, Cost=Distance[cite: 59, 60, 61, 62, 63, 292, 293, 294].
    * **Vacuum World:** States=Location & Dirt status, Actions=Left, Right, Suck, Goal=All clean, Cost=1 per action[cite: 64, 297, 298, 299].
    * **8-Puzzle:** States=Tile locations, Actions=Move blank, Goal=Specific configuration, Cost=1 per move[cite: 65, 300, 301, 302].
    * **8-Queens:** Place 8 queens so none attack. Goal=8 non-attacking queens, Cost=0[cite: 66, 304].
        * *Incremental Formulation:* Start empty, add queens one by one[cite: 66, 304].
        * *Complete-State Formulation:* Start with 8 queens, move them[cite: 67, 305]. (Formulation impacts search space size significantly)[cite: 68, 306].
    * **Water Pouring:** Measure exactly 2 gallons using 3 & 4-gallon buckets. States=(gallons in 3, gallons in 4), Actions=Fill, Empty, Pour, Goal=(x, 2) or (2, x), Cost=1 per step[cite: 306, 307, 31].
    * **Pegs and Disks (Tower of Hanoi variant):** Move disks between pegs with constraints[cite: 289, 290, 291].
    * **Robotic Assembly:** States=Joint angles, object parts; Actions=Continuous joint movements; Goal=Complete assembly; Cost=Time[cite: 303].
    * **River Crossing:** Man, Wolf, Corn, Chicken crossing a river with constraints (Max 2 in boat, Wolf eats Chicken, Chicken eats Corn)[cite: 69, 70].
* **Search Strategy Evaluation:** [cite: 75]
    * **Completeness:** Guaranteed to find a solution if one exists?[cite: 76].
    * **Optimality:** Finds the highest-quality (e.g., lowest cost) solution?[cite: 76].
    * **Time Complexity:** How long does it take? (Often measured in nodes generated/expanded)[cite: 77].
    * **Space Complexity:** How much memory is needed? (Often measured in max nodes stored)[cite: 78].
    * Complexity often expressed in terms of: $b$ (branching factor), $d$ (depth of shallowest solution), $m$ (maximum depth of state space).
* **Uninformed Search Strategies:** [cite: 79] (Use only problem definition)
    * **Breadth-First Search (BFS):** [cite: 80]
        * Expands shallowest unexpanded node first (FIFO queue for fringe).
        * Complete: Yes (if $b$ is finite)[cite: 82].
        * Time: $O(b^{d+1})$[cite: 82].
        * Space: $O(b^{d+1})$ (keeps all nodes in memory)[cite: 82].
        * Optimal: Yes (if cost=1 per step)[cite: 83].
        * Space is often the main limitation[cite: 83, 84].
    * **Uniform Cost Search (UCS):** [cite: 84]
        * Expands the node $n$ with the lowest path cost $g(n)$.
        * Uses a priority queue for the fringe.
        * Complete: Yes (if step costs $\ge \epsilon > 0$).
        * Time: $O(b^{1 + \lfloor C^*/\epsilon \rfloor})$ where $C^*$ is cost of optimal solution.
        * Space: $O(b^{1 + \lfloor C^*/\epsilon \rfloor})$.
        * Optimal: Yes.
        * Essentially BFS if all step costs are equal[cite: 84]. Doesn't work well with negative costs[cite: 84].
    * **Depth-First Search (DFS):** [cite: 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95]
        * Expands the deepest unexpanded node first (LIFO queue for fringe)[cite: 86].
        * Can use backtracking (generate one successor at a time) to save memory[cite: 85].
        * Complete: No (fails in infinite spaces/loops). Complete in finite spaces if modified to avoid cycles[cite: 97].
        * Time: $O(b^m)$ (terrible if $m$ is much larger than $d$, but can be faster than BFS if solutions are dense)[cite: 98].
        * Space: $O(bm)$ (linear space complexity is a major advantage!)[cite: 99].
        * Optimal: No[cite: 99].
    * **Depth-Limited Search (DLS):**
        * DFS with a pre-imposed depth limit $l$. Nodes at depth $l$ are treated as having no successors.
        * Solves the infinite path problem of DFS.
        * Complete: No (if shallowest goal $d > l$).
        * Time: $O(b^l)$.
        * Space: $O(bl)$.
        * Optimal: No.
        * Requires choosing a good limit $l$.
    * **Iterative Deepening Search (IDS):** [cite: 100]
        * Combines benefits of BFS and DFS[cite: 100].
        * Performs DLS for depth limits 0, 1, 2, ... until a goal is found[cite: 100].
        * Complete: Yes[cite: 102].
        * Time: $O(b^d)$ (same order as BFS, but surprisingly efficient as most nodes are in the bottom level)[cite: 102].
        * Space: $O(bd)$ (same as DFS)[cite: 102].
        * Optimal: Yes (if step cost = 1)[cite: 103].
        * Generally the preferred uninformed search when the search space is large and solution depth is unknown[cite: 101].
    * **Bidirectional Search:** [cite: 104]
        * Runs two searches: one forward from initial state, one backward from goal[cite: 104].
        * Stops when they meet[cite: 104].
        * Needs reversible actions and ability to compute predecessors[cite: 104]. Goal might be implicitly defined or too numerous.
        * Time/Space: $O(b^{d/2})$ (potentially much faster)[cite: 105].

### **Hill climbing.pptx**

* **Optimization / Iterative Improvement / Local Search:** [cite: 32]
    * Framework usually involves working with a single state in memory[cite: 33].
    * Generates new states from the current one, attempting to improve[cite: 33].
    * Goal is typically to optimize an objective/cost function[cite: 33].
* **Hill Climbing:** [cite: 34, 40]
    * A local, greedy search algorithm; does not backtrack[cite: 40].
    * Variant of generate-and-test, using feedback from a heuristic function to guide search direction[cite: 35, 36].
    * Often used when a good heuristic is available but other knowledge is limited[cite: 37].
    * Example: Finding downtown in an unfamiliar city by always moving towards it (heuristic = distance)[cite: 38, 39].
    * **Algorithm:** [cite: 43, 44]
        1.  Evaluate the initial state[cite: 44].
        2.  Loop:
            * Generate neighboring successor states[cite: 41].
            * Select the neighbor with the highest value (best evaluation)[cite: 41, 43].
            * If the best neighbor's value is not better than the current state's value, return the current state (local maximum reached)[cite: 43, 44].
            * Otherwise, set the best neighbor as the current state and continue[cite: 43, 44].
    * **Successor Function:** Defines the "neighborhood" and is crucial for performance. Needs to balance preserving good parts of the solution and allowing exploration[cite: 45, 46].
* **Problems/Limitations:** [cite: 47]
    * Can get stuck depending on the initial state.
    * **Local Maximum:** A state better than all its neighbors but not the global optimum[cite: 47, 48]. Can occur close to the actual solution[cite: 48].
    * **Plateau:** A flat area where neighbors have the same value, making it impossible to choose the best direction based on local comparison[cite: 49, 50].
    * **Ridge:** A path where the search space is higher than surrounding areas but has a slope that single moves cannot easily traverse uphill[cite: 51, 52].

### **AO Star Algorithm.pdf**

* **Introduction:**
    * An informed search algorithm, works like best-first search[cite: 2].
    * Based on problem decomposition (breaking problem into smaller pieces)[cite: 3].
    * Efficient method for exploring solution paths[cite: 4].
    * Used in pathfinding (e.g., video games), graph traversal, NLP parsing (stochastic grammars), online learning searches, game trees, problem solving[cite: 4, 5, 6].
* **AND-OR Graphs:** [cite: 7]
    * Used for problems solvable by decomposing into subproblems[cite: 7].
    * Nodes represent problems/subproblems.
    * **AND arcs:** Link a node to a set of successor nodes *all* of which must be solved[cite: 7, 8].
    * **OR arcs:** Link a node to successor nodes where solving *any one* is sufficient.
    * Example: To "Own Mobile Phone", you must "Earn Money" AND "Buy mobile phone" (OR you could "Steal It")[cite: 8].
    * Nodes have associated heuristic values ($h(n)$) and edge/actual costs ($g(n)$)[cite: 10, 11]. The cost function is $f(n) = g(n) + h(n)$[cite: 10].
* **AO* Algorithm Steps:** [cite: 20, 21, 22, 23]
    1.  Initialize the graph to the start node[cite: 20].
    2.  Traverse the graph following the current best path, accumulating nodes not yet expanded or solved[cite: 20].
    3.  Pick an unexpanded node on the current path and expand it. If it has no successors, assign it a value (e.g., FUTILITY). Otherwise, calculate $f'$ (estimated cost) for successors[cite: 20].
    4.  If a node's calculated cost ($f'$) indicates it's solved (e.g., cost is 0 or meets goal condition), mark it SOLVED[cite: 21].
    5.  Propagate cost changes back up the graph: update the $f'$ value of the parent based on its successors. For AND nodes, sum costs; for OR nodes, take the minimum cost[cite: 21]. Mark the most promising path.
    6.  If a node is marked SOLVED, mark its parent as SOLVED if appropriate (e.g., all successors under an AND arc are solved)[cite: 22].
    7.  If the starting node is SOLVED or its cost exceeds FUTILITY, stop. Otherwise, repeat from step 2[cite: 23].
    * The algorithm doesn't necessarily explore all solution paths once one is found[cite: 16]. Cost revision happens during backpropagation (Examples 1 & 2 illustrate this)[cite: 13, 15].
* **AO* vs. A*:** [cite: 24, 28]
    * **A*:** For OR graphs, finds a *single* solution path. Used for path-finding, graph traversal[cite: 24, 25, 26]. Traverses depth, accumulating cost ($g(n)+h(n)$)[cite: 27].
    * **AO*:** For AND-OR graphs, finds a solution that might involve *multiple* branches (due to AND constraints)[cite: 28]. Cost calculation involves summing costs for AND branches[cite: 30].

### **Lecture Series Natural Langauge Processing (1) (1).pptx**

* **Introduction to NLP:** [cite: 111]
    * Field of AI enabling computers to understand, interpret, generate human language[cite: 130].
    * Intersection of linguistics, computer science, machine learning[cite: 131].
* **Language Basics:**
    * Vocabulary: Set of words[cite: 145].
    * Text: Sequence of words from a vocabulary[cite: 145].
    * Language: Set of all possible texts[cite: 145].
* **Text Preprocessing & Fundamentals:** [cite: 183]
    * **Tokenization:** Breaking text into units (words, punctuation)[cite: 181, 183, 187].
    * **Stop Word Removal:** Removing common words (e.g., 'the', 'a', 'is') that carry little semantic weight[cite: 184, 188].
    * **Stemming:** Crude chopping of word endings to get a common base form (e.g., consult, consultant, consulting -> consult)[cite: 112, 185]. Just removes suffixes[cite: 113].
    * **Lemmatization:** Reducing words to their dictionary/base form (lemma) using vocabulary and morphological analysis (e.g., studies, studying -> study)[cite: 113, 185]. Uses grammatical information[cite: 113].
    * **Handling Noise/Errors:** Cleaning typos, abbreviations, etc.[cite: 186].
    * **Part-of-Speech (POS) Tagging:** Identifying grammatical roles (noun, verb, adjective)[cite: 147, 182].
* **Core NLP Tasks & Applications:**
    * **Language Translation:** Breaking language barriers[cite: 114, 125, 126, 147].
    * **Summarization:** Generating concise summaries of documents[cite: 115, 128, 147].
    * **Chatbots & Virtual Assistants:** Understanding and responding naturally[cite: 116].
    * **Sentiment Analysis:** Determining positive/negative/neutral tone[cite: 117, 120]. Challenges: sarcasm, context[cite: 119].
    * **Emotion Detection:** Identifying specific emotions (joy, anger, sadness)[cite: 118].
    * **Named Entity Recognition (NER):** Identifying names of people, organizations, locations, etc.[cite: 121, 122, 147].
    * **Information Extraction (IE):** Extracting structured data, relationships, and events from text[cite: 121, 123, 124, 147].
    * **Relationship Extraction:** Identifying connections between entities[cite: 123, 141].
    * **Event Extraction:** Finding events, participants, details[cite: 124].
    * **Natural Language Generation (NLG):** Producing human-like text[cite: 127].
    * **Code Generation:** Translating natural language to code[cite: 129].
    * **Spell & Grammar Checking:** Identifying errors, suggesting corrections[cite: 129].
    * **Word Prediction:** Suggesting next likely word during typing[cite: 129].
    * **Information Retrieval (IR):** Finding relevant information for a query[cite: 132].
    * **Text Categorization:** Assigning predefined categories to text[cite: 132].
    * **Question Answering (QA):** Answering questions posed in natural language (e.g., IBM Watson)[cite: 147].
    * **Optical Character Recognition (OCR):** Converting images of text to machine-readable text[cite: 147].
    * **Speech Recognition:** Transcribing spoken language to text[cite: 133].
    * **Speech Synthesis:** Generating spoken language from text[cite: 147].
    * **Spoken Dialog Systems:** Enabling conversation between user and system[cite: 147].
* **Levels of Analysis:**
    * **Semantic Analysis:** Understanding the *meaning* of language[cite: 133, 136, 182]. Takes context, structure, grammar into account[cite: 136].
        * *Lexical Semantics:* Meaning of individual words[cite: 137, 138].
        * *Compositional Semantics:* How word meanings combine to form sentence meaning[cite: 139].
        * *Tasks:* Word Sense Disambiguation (determining correct meaning of words like 'bank' or 'bark' in context)[cite: 140], Relationship Extraction[cite: 141], Semantic Role Labeling (identifying subject-predicate-object structures)[cite: 142].
        * *Disclosure Integration:* Resolving references, especially pronouns ('He liked it' - what does 'He' and 'it' refer to?)[cite: 143, 144].
    * **Pragmatic Analysis:** Understanding meaning based on context, situation, and real-world knowledge (social use of language)[cite: 146, 148]. Example: "The average is 18" could mean different things depending on context[cite: 147]. "Give me the salt!" vs "Could you please give me the salt?"[cite: 148].
    * **Syntax:** Grammatical structure of sentences. Syntax analysis (parsing) helps resolve ambiguity (e.g., "I saw the man with a telescope" - who has the telescope?)[cite: 151].
* **Challenges in NLP:**
    * **Ambiguity:** Words or sentences having multiple meanings (lexical, syntactic, semantic, pragmatic)[cite: 150, 151].
    * **Paraphrasing:** Different words/sentences expressing the same meaning[cite: 149, 150].
    * Context dependency, sarcasm, world knowledge requirements.
* **NLP Skills & Job Market:** [cite: 157]
    * High demand for NLP skills in various industries[cite: 157].
    * Roles: NLP Engineer, Data Scientist, Computational Linguist[cite: 159, 160].
    * Requires technical skills (ML, Python, deep learning) and linguistic understanding[cite: 166, 167]. Educational background in CS, Linguistics valued[cite: 168].
    * Often commands high salaries and good benefits[cite: 162, 163, 164].
    * Future outlook is strong due to rising demand and technological advancements[cite: 169, 170, 171].
    * Training options: University programs, online courses, workshops[cite: 172, 173, 174].


